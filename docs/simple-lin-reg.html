<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.1 Simple Linear Regression | An Introduction to Statistical Learning: with Applications in R</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="3.1 Simple Linear Regression | An Introduction to Statistical Learning: with Applications in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="MokeEire/BookdownISL" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.1 Simple Linear Regression | An Introduction to Statistical Learning: with Applications in R" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Gareth James, Daniela Witten, Trevor Hastie, &amp; Robert Tibshirani" />


<meta name="date" content="2020-11-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linreg.html"/>
<link rel="next" href="mult-lin-reg.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide' : 'Code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://faculty.marshall.usc.edu/gareth-james/ISL/">An Introduction to Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="3.1.1" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#simple-coef-est"><i class="fa fa-check"></i><b>3.1.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#assess-coef-acc"><i class="fa fa-check"></i><b>3.1.2</b> Assessing the Accuracy of the Coefficient Estimates</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#assess-model-acc"><i class="fa fa-check"></i><b>3.1.3</b> Assessing the Accuracy of the Model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="mult-lin-reg.html"><a href="mult-lin-reg.html"><i class="fa fa-check"></i><b>3.2</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="3.2.1" data-path="mult-lin-reg.html"><a href="mult-lin-reg.html#est-reg-coef"><i class="fa fa-check"></i><b>3.2.1</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="3.2.2" data-path="mult-lin-reg.html"><a href="mult-lin-reg.html#important-questions"><i class="fa fa-check"></i><b>3.2.2</b> Some Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="other-reg-cons.html"><a href="other-reg-cons.html"><i class="fa fa-check"></i><b>3.3</b> Other Considerations in the Regression Model</a><ul>
<li class="chapter" data-level="3.3.1" data-path="other-reg-cons.html"><a href="other-reg-cons.html#qualitative-predictors"><i class="fa fa-check"></i><b>3.3.1</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="3.3.2" data-path="other-reg-cons.html"><a href="other-reg-cons.html#extensions-of-the-linear-model"><i class="fa fa-check"></i><b>3.3.2</b> Extensions of the Linear Model</a></li>
<li class="chapter" data-level="3.3.3" data-path="other-reg-cons.html"><a href="other-reg-cons.html#potential-problems"><i class="fa fa-check"></i><b>3.3.3</b> Potential Problems</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="the-marketing-plan.html"><a href="the-marketing-plan.html"><i class="fa fa-check"></i><b>3.4</b> The Marketing Plan</a></li>
<li class="chapter" data-level="3.5" data-path="comparison-of-linear-regression-with-k-nearest-neighbors.html"><a href="comparison-of-linear-regression-with-k-nearest-neighbors.html"><i class="fa fa-check"></i><b>3.5</b> Comparison of Linear Regression with K-Nearest Neighbors</a></li>
<li class="chapter" data-level="3.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html"><i class="fa fa-check"></i><b>3.6</b> Lab: Linear Regression</a><ul>
<li class="chapter" data-level="3.6.1" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#libraries"><i class="fa fa-check"></i><b>3.6.1</b> Libraries</a></li>
<li class="chapter" data-level="3.6.2" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>3.6.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.6.3" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>3.6.3</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="3.6.4" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>3.6.4</b> Interaction Terms</a></li>
<li class="chapter" data-level="3.6.5" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#qualitative-predictors-1"><i class="fa fa-check"></i><b>3.6.5</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="3.6.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#writing-functions"><i class="fa fa-check"></i><b>3.6.6</b> Writing Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning: with Applications in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-lin-reg" class="section level2">
<h2><span class="header-section-number">3.1</span> Simple Linear Regression</h2>
<p><em>Simple linear regression</em> lives up to its name: it is a very straightforward approach for predicting a quantitative response <em>Y</em> on the basis of a single predictor variable <em>X</em>.
It assumes that there is an approximately linear relationship between <em>X</em> and <em>Y</em>.
Mathematically we can write this linear relationship as</p>
<p><span class="math display" id="eq:linmod">\[\begin{equation} 
  Y \approx \beta_0 + \beta_1X
  \tag{3.1}
\end{equation}\]</span></p>
<p>You might read “<span class="math inline">\(\approx\)</span>” as “<em>is approximately modeled as</em>”.
We will sometimes describe <a href="simple-lin-reg.html#eq:linmod">(3.1)</a> by saying we are <em>regressing</em> Y on X (or Y <em>onto</em> X).
For example, <em>X</em> may represent <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> advertising and <em>Y</em> may represent <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong>.
Then we can regress <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> onto <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> by fitting the model:</p>
<p><span class="math display">\[\color{#B44C1C}{\textbf{sales}} = \beta_0+\beta_1\times\color{#B44C1C}{\textbf{TV}}\]</span></p>
<p>In Equation <a href="simple-lin-reg.html#eq:linmod">(3.1)</a>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are two unknown constants that represent the <em>intercept</em> and the <em>slope</em> terms in the linear model.
Together, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are known as the model <em>coefficients</em> or <em>parameters</em>.
Once we have used our training data to produce estimates <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> for our model parameters, we can predict future sales on the basis of a particular value of TV advertising by computing</p>
<p><span class="math display" id="eq:linest">\[\begin{equation} 
  \hat{y} = \hat{\beta_0} + \hat{\beta_1}x
  \tag{3.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\hat{y}\)</span> indicates a prediction of <span class="math inline">\(Y\)</span> on the basis of <span class="math inline">\(X=x\)</span>.
Here we use the <em>hat</em> symbol, ^ , to denote the estimated value of an unknown parameter or coefficient, or to denote the predicted value of the response.</p>
<div id="simple-coef-est" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Estimating the Coefficients</h3>
<p>In practice, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown.
So before we can use <a href="simple-lin-reg.html#eq:linmod">(3.1)</a> to make predictions, we must use data to estimate the coefficients. Let</p>
<p><span class="math display">\[(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\]</span></p>
<p>represent <em>n</em> observation pairs, each of which consists of a measurement of <em>X</em> and a measurement of <em>Y</em>.
In the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> example, this data set consists of the TV advertising budget and product sales in <span class="math inline">\(n = 200\)</span> different markets.
(Recall that the data are displayed in <strong>Figure 2.1</strong>.)
Our goal is to obtain coefficient estimates <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> such that the linear model <a href="simple-lin-reg.html#eq:linmod">(3.1)</a> fits the available data well—that is, so that <span class="math inline">\(y_i \approx \hat{\beta_0}+\hat{\beta_1}x_i\)</span> for <span class="math inline">\(i = 1,...,n\)</span>.
In other words, we want to find an intercept b0 and a slope b1 such that the resulting line is as close as possible to the <span class="math inline">\(n = 200\)</span> data points.
There are a number of ways of measuring <em>closeness</em>.
However, by far the most common approach involves minimizing the <em>least squares</em> criterion, and we take that approach in this chapter.
Alternative approaches will be considered in Chapter 6.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="simple-lin-reg.html#cb2-1"></a><span class="co"># Fit linear model regressing Sales on TV</span></span>
<span id="cb2-2"><a href="simple-lin-reg.html#cb2-2"></a>adv_lm =<span class="st"> </span><span class="kw">lm</span>(sales<span class="op">~</span>TV, advertising)</span>
<span id="cb2-3"><a href="simple-lin-reg.html#cb2-3"></a></span>
<span id="cb2-4"><a href="simple-lin-reg.html#cb2-4"></a><span class="co"># Add the predicted values to the advertising dataframe</span></span>
<span id="cb2-5"><a href="simple-lin-reg.html#cb2-5"></a>advertising <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2-6"><a href="simple-lin-reg.html#cb2-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predicted =</span> adv_lm<span class="op">$</span>fitted.values) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2-7"><a href="simple-lin-reg.html#cb2-7"></a><span class="st">  </span><span class="kw">ggplot</span>(., <span class="kw">aes</span>(<span class="dt">x=</span>TV, <span class="dt">y =</span> sales))<span class="op">+</span></span>
<span id="cb2-8"><a href="simple-lin-reg.html#cb2-8"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>)<span class="op">+</span></span>
<span id="cb2-9"><a href="simple-lin-reg.html#cb2-9"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">xend =</span> TV, <span class="dt">yend =</span> predicted), <span class="dt">colour =</span> <span class="st">&quot;grey40&quot;</span>)<span class="op">+</span></span>
<span id="cb2-10"><a href="simple-lin-reg.html#cb2-10"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> F, <span class="dt">fullrange =</span> T)<span class="op">+</span></span>
<span id="cb2-11"><a href="simple-lin-reg.html#cb2-11"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">n.breaks =</span> <span class="dv">6</span>)<span class="op">+</span></span>
<span id="cb2-12"><a href="simple-lin-reg.html#cb2-12"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">15</span>,<span class="dv">20</span>,<span class="dv">25</span>))<span class="op">+</span></span>
<span id="cb2-13"><a href="simple-lin-reg.html#cb2-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Sales&quot;</span>)<span class="op">+</span></span>
<span id="cb2-14"><a href="simple-lin-reg.html#cb2-14"></a><span class="st">  </span><span class="co"># theme_bw(base_size = 14, base_family = &quot;Roboto&quot;)</span></span>
<span id="cb2-15"><a href="simple-lin-reg.html#cb2-15"></a><span class="st">  </span><span class="kw">theme_islr</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:advertising-lm"></span>
<img src="BookdownISL_files/figure-html/advertising-lm-1.png" alt="*For the &lt;strong&gt;&lt;span style='font-family:monospace; color: #B44C1C;'&gt;Advertising&lt;/span&gt;&lt;/strong&gt; data, the least squares fit for the regression of &lt;strong&gt;&lt;span style='font-family:monospace; color: #B44C1C;'&gt;sales&lt;/span&gt;&lt;/strong&gt; onto &lt;strong&gt;&lt;span style='font-family:monospace; color: #B44C1C;'&gt;TV&lt;/span&gt;&lt;/strong&gt; is shown.  The fit is found by minimizing the sum of squared errors.  Each grey line segment represents an error, and the fit makes a compromise by averaging their squares.  In this case a linear fit captures the essence of the relationship, although it is somewhat deficient in the left of the plot.*" width="1152" />
<p class="caption">
FIGURE 3.1: <em>For the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> data, the least squares fit for the regression of <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> onto <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> is shown. The fit is found by minimizing the sum of squared errors. Each grey line segment represents an error, and the fit makes a compromise by averaging their squares. In this case a linear fit captures the essence of the relationship, although it is somewhat deficient in the left of the plot.</em>
</p>
</div>
<p>Let <span class="math inline">\(\hat{y_i} = \hat{\beta_0}+\hat{\beta_1}x_i\)</span> be the prediction for <span class="math inline">\(Y\)</span> based on the <em>i</em>th value of <span class="math inline">\(X\)</span>.
Then <span class="math inline">\(e_i = y_i - \hat{y_i}\)</span> represents the <em>i</em>th <em>residual</em>—this is the difference between the <em>i</em>th observed response value and the <em>i</em>th response value that is predicted by our linear model.
We define the <em>residual sum of squares</em> (RSS) as
<span class="math display">\[RSS = {e_1^2}+{e_2^2}+...+{e_n^2},\]</span>
or equivalently as</p>
<p><span class="math display" id="eq:rss">\[\begin{equation} 
  RSS = (y_1 - \hat{\beta_0} - \hat{\beta_1}x_1)^2 + (y_2 - \hat{\beta_0} - \hat{\beta_1}x_2)^2 + ... + (y_n - \hat{\beta_0} - \hat{\beta_1}x_n)^2.
  \tag{3.3}
\end{equation}\]</span></p>
<p>The least squares approach chooses <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> to minimize the RSS.
Using some calculus, one can show that the minimizers are</p>
<p><span class="math display" id="eq:rssmin">\[\begin{equation} 
\begin{aligned}
  \hat{\beta_1} &amp;= \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2},\\
  \hat{\beta_0} &amp;= \bar{y}-\hat{\beta_1}\bar{x},
  \end{aligned}
  \tag{3.4}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\bar{y} \equiv \frac{1}{n}\sum_{i=1}^{n}y_i\)</span> and <span class="math inline">\(\bar{x} \equiv \frac{1}{n}\sum_{i=1}^{n}x_i\)</span> are the sample means.
In other words, <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a> defines the <em>least squares coefficient estimates</em> for simple linear regression.</p>
<p><a href="simple-lin-reg.html#fig:advertising-lm">3.1</a> displays the simple linear regression fit to the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> data, where <span class="math inline">\(\hat{\beta_0} = 7.03\)</span> and <span class="math inline">\(\hat{\beta_1} = 0.0475\)</span>.
In other words, according to this approximation, an additional $1,000 spent on TV advertising is associated with selling approximately 47.5 additional units of the product.
In <strong>Figure 3.2</strong>, we have computed RSS for a number of values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, using the advertising data with <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> as the response and <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> as the predictor.
In each plot, the red dot represents the pair of least squares estimates <span class="math inline">\((\hat{\beta_0}, \hat{\beta_1})\)</span> given by <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a>.
These values clearly minimize the RSS.</p>
</div>
<div id="assess-coef-acc" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Assessing the Accuracy of the Coefficient Estimates</h3>
<p>Recall from <strong>Equation (2.1)</strong> that we can assume that the <em>true</em> relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> takes the form <span class="math inline">\(Y = f(X)+\epsilon\)</span> for some unknown function <span class="math inline">\(f\)</span>, where <span class="math inline">\(\epsilon\)</span> is a mean-zero random error term.
If <span class="math inline">\(f\)</span> is to be approximated by a linear function, then we can write this relationship as</p>
<p><span class="math display" id="eq:lin-rel">\[\begin{equation}
  Y = \beta_0+\beta_1X + \epsilon.
  \tag{3.5}
\end{equation}\]</span></p>
<p>Here <span class="math inline">\(\beta_0\)</span> is the intercept term—that is, the expected value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X=0\)</span> and <span class="math inline">\(\beta_1\)</span> is the slope—the average increase in <span class="math inline">\(Y\)</span> associated with a one-unit increase in <span class="math inline">\(X\)</span>.
The error term is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that cause variation in <span class="math inline">\(Y\)</span>, and there may be measurement error.
We typically assume that the error term is independent of <span class="math inline">\(X\)</span>.
The model given by <a href="simple-lin-reg.html#eq:lin-rel">(3.5)</a> defines the <em>population regression line</em>, which is the best linear approximation to the true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
The least squares regression coefficient estimates <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a> characterize the <em>least squares line</em> <a href="simple-lin-reg.html#eq:linest">(3.2)</a>.
The left-hand panel of <strong>Figure 3.3</strong> displays these two lines in a simple simulated example. We created 100 random Xs, and generated 100 corresponding Ys from the model</p>
<p><span class="math display" id="eq:sim-mod">\[\begin{equation}
  Y = 2+3X+\epsilon
  \tag{3.6}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> was generated from a normal distribution with mean zero.
The red line in the left-hand panel of Figure 3.3 displays the <em>true</em> relationship, <span class="math inline">\(f(X) = 2 + 3X\)</span>, while the blue line is the least squares estimate based on the observed data.
The true relationship is generally not known for real data, but the least squares line can always be computed using the coefficient estimates given in <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a>.
In other words, in real applications, we hav eaccess to a set of observations from which we can compute the lease squares line; however, the population regression line is unobserved.
In the right-hand panel of Figure 3.3 we have generated ten different data sets from the model given by <a href="simple-lin-reg.html#eq:sim-mod">(3.6)</a> and plotted the corresponding ten least squares lines.
Notice that different data sets generated from the same true model result in slightly different least squares lines, but the unobserved population regression line does not change.</p>
<p>At first glance, the difference between the population regression line and the least squares line may seem subtle and confusing.
We only have one data set, and so what does it mean that two different lines describe the relationship between the predictor and the response?
Fundamentally the concept of these two lines is a natural extension of the standard statistical approach of using information from a sample to estimate characteristics of a large population.
For example, suppose that we are interested in knowing the population mean <span class="math inline">\(\mu\)</span> of some random variable <span class="math inline">\(Y\)</span>.<br />
Unfortunately, <span class="math inline">\(\mu\)</span> is unknoqn, but we do have access to <span class="math inline">\(n\)</span> observations from <span class="math inline">\(Y\)</span>, which we can write as <span class="math inline">\(y_1, ..., y_n\)</span>, and which we can use to estimate <span class="math inline">\(\mu\)</span>.
A reasonable estimate is <span class="math inline">\(\hat{\mu} = \bar{y}\)</span>, where <span class="math inline">\(\bar{y} = \frac{1}{n}\sum^{n}_{i=1}{y_i}\)</span> is the sample mean.
The sample mean and the population mean are different, but in general the sample mean will provide a good estimate of the population mean.
In the same way, the unknown coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in linear regression define the population regression line.
We seek to estimate these unknown coefficients using <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> given in <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a>.
These coefficient estimates define the least squares line.</p>
<p>The analogy between linear regression and estimation of the mean of a random variable is an apt one based on the concept of <em><strong>bias</strong></em>.
If we use the sample mean <span class="math inline">\(\hat{\mu}\)</span> to estimate <span class="math inline">\(\mu\)</span>, this estimate is <em><strong>unbiased</strong></em>, in the sense that on average, we expect <span class="math inline">\(\hat{\mu}\)</span> to equal <span class="math inline">\(\mu\)</span>.
What exactly does this mean?
It means that on the basis of one particular set of observations <span class="math inline">\(y_1,...,y_n,\; \hat{\mu}\)</span> might overestimate <span class="math inline">\(\mu\)</span>, and on the basis of another set of observations, <span class="math inline">\(\hat{\mu}\)</span> might underestimate <span class="math inline">\(\mu\)</span>.
But if we could average a huge number of estimates of <span class="math inline">\(\mu\)</span> obtained from a huge number of sets of observations, then this average would <em>exactly</em> equal <span class="math inline">\(\mu\)</span>.
Hence, an unbiased estimator does not _systematically) over- or under-estimate the true parameter.
The property of unbiasedness holds for the least squares coefficient estimates given by <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a> as well: if we estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> on the basis of a particular data set, then the average of these estimates would be spot on!<br />
In fact, we can see from the right-hand panel on Figure 3.3 that the average of many least squares lines, each estimated from a separate data set, is pretty close to the true population regression line.</p>
<p>We continue the analogy with the estimation of the population mean <span class="math inline">\(\mu\)</span> of a random variable <span class="math inline">\(Y\)</span>.<br />
A natural question is as follows: how accurate is the sample mean <span class="math inline">\(\hat{\mu}\)</span> as an estimate of <span class="math inline">\(\mu\)</span>?
We have established that the average of <span class="math inline">\(\hat{\mu}\)</span>’s over many data sets will be very close to <span class="math inline">\(\mu\)</span>, but that a single estimate <span class="math inline">\(\hat{\mu}\)</span> may be a substantial underestimate or overestimate of <span class="math inline">\(\mu\)</span>.
How far off will that single estimate of <span class="math inline">\(\hat{\mu}\)</span> be?
In general, we answer this question by computing the <em>standard error</em> of <span class="math inline">\(\hat{\mu}\)</span>, written as <span class="math inline">\(SE(\hat{\mu})\)</span>.
We have the well-known formula</p>
<p><span class="math display" id="eq:mu-se">\[\begin{equation}
Var(\hat{\mu}) = SE(\hat{\mu})^2 = \frac{\sigma^2}{n} \tag{3.7}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the standard deviation of each of the realizations <span class="math inline">\(y_i\)</span> of <span class="math inline">\(Y\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>
Roughly speaking, the standard error tells us the average amount that this estimate <span class="math inline">\(\hat{\mu}\)</span> differs from the actual value of <span class="math inline">\(\mu\)</span>.
Equation <a href="simple-lin-reg.html#eq:mu-se">(3.7)</a> also tells us how this deviation shrinks with <em>n</em>—themore observations we have, the smaller the standard error of <span class="math inline">\(\hat{\mu}\)</span>.
In a similar vein, we can wonder how close <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> are to the true values <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>/
To compute the standard errors associated with <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span>, we use the following formulas:</p>
<p><span class="math display" id="eq:beta-se">\[\begin{equation}
SE(\hat{\beta_0})^2 = \sigma^2 \left[ \frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} \right] , 
\hspace{1cm} 
SE(\hat{\beta_1})^2 = \frac{\sigma^2}{\sum_{i=1}^n (x_i - \bar{x})^2} , \tag{3.8}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\sigma^2 = Var(\epsilon)\)</span>.
For these formulas to be strictly valid, we need to assume that the errors <span class="math inline">\(\epsilon_i\)</span> for each observation are uncorrelated with common variance <span class="math inline">\(\sigma^2\)</span>.
This is clearly not true in Figure <a href="simple-lin-reg.html#fig:advertising-lm">3.1</a>, but the formula still turns out to be a good approximation.
Notice in the formula that <span class="math inline">\(SE(\hat{\beta_1}\)</span> is smaller when the <span class="math inline">\(x_i\)</span> are more spread out; intuitively we have more <em>leverage</em> to estimate a slope when this is the case.
We also see that <span class="math inline">\(SE(\hat{\beta_0})\)</span> would be the same as <span class="math inline">\(SE(\hat{\mu})\)</span> if <span class="math inline">\(\bar{x}\)</span> were zero (in which case <span class="math inline">\(\hat{\beta_0}\)</span> would be equal to <span class="math inline">\(\bar{y}\)</span>).
In general, <span class="math inline">\(\sigma^2\)</span> is not known, but can be estimated from the data.
The estimate of <span class="math inline">\(\sigma\)</span> is known as the <em>residual standard error</em>, and is given by the formula <span class="math inline">\(RSE = \sqrt{RSS/(n-2)}\)</span>.
Strictly speaking, when <span class="math inline">\(\sigma^2\)</span> is estimated from the data we should write <span class="math inline">\(\widehat{SE}(\hat{\beta_1})\)</span> to indicate that an estimate has been made, but for simplicity of notation we will drop this extra “hat”.</p>
<p>Standard errors can be used to compute <em>confidence intervals</em>.
A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter.
The range is defined in terms of lower and upper limits computed from the sample of data.
For linear regression, the 95% confidence interval for <span class="math inline">\(\beta_1\)</span> approximately takes the form</p>
<p><span class="math display" id="eq:b1-ci">\[\begin{equation}
\hat{\beta_1} \pm 2 \cdot SE(\hat{\beta_1}). \tag{3.9}
\end{equation}\]</span></p>
<p>That is, there is approximately a 95% chance that the interval</p>
<p><span class="math display" id="eq:b1-interval">\[\begin{equation}
\left[ \hat{\beta_1} - 2 \cdot SE(\hat{\beta_1}), \hat{\beta_1} + 2 \cdot SE(\hat{\beta_1}) \right] \tag{3.10}
\end{equation}\]</span></p>
<p>will contain the true value of <span class="math inline">\(\beta_1\)</span>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>
Similarly, a confidence interval for <span class="math inline">\(\beta_0\)</span> approximately takes the form</p>
<p><span class="math display" id="eq:b0-ci">\[\begin{equation}
\hat{\beta_0} \pm 2 \cdot SE(\hat{\beta_0}). \tag{3.11}
\end{equation}\]</span></p>
<p>In the case of the advertising data, the 95% confidence interval for <span class="math inline">\(\beta_0\)</span> is <span class="math inline">\([6.130, 7.935]\)</span> and the 95% confidence interval for <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\([0.042, 0.053]\)</span>.
Therefore, we can conclude that in the absence of any advertising, sales will, on average, fall somewhere between 6,130 and 7,940 units.
Furthermore, for each $1,000 increase in television advertising, there will be an average increase in sales of between 42 and 53 units.</p>
<p>Standard errors can also be used to perform <em>hypothesis tests</em> on the coefficients.
The most common hypothesis test involves testing the <em>null hypothesis</em> of</p>
<p><span class="math display" id="eq:h-null">\[\begin{equation}
H_0: \mathrm{There\ is\ no\ relationship\ between}\ X\ \mathrm{and}\ Y \tag{3.12}
\end{equation}\]</span></p>
<p>versus the <em>alternative hypothesis</em></p>
<p><span class="math display" id="eq:h-a">\[\begin{equation}
H_a: \mathrm{There\ is\ some\ relationship\ between}\ X\ \mathrm{and}\ Y. \tag{3.13}
\end{equation}\]</span></p>
<p>Mathematically, this corresponds to testing</p>
<p><span class="math display">\[H_0: \beta_1 = 0\]</span></p>
<p>versus</p>
<p><span class="math display">\[H_a: \beta_1 \neq 0.\]</span></p>
<p>since if <span class="math inline">\(\beta_1 = 0\)</span> then the model <a href="simple-lin-reg.html#eq:lin-rel">(3.5)</a> reduces to <span class="math inline">\(Y = \beta_0 + \epsilon\)</span>, and <span class="math inline">\(X\)</span> is not associated with <span class="math inline">\(Y\)</span>.
To test the null hypothesis, we need to determine whether <span class="math inline">\(\hat{\beta_1}\)</span>, our estimate for <span class="math inline">\(\beta_1\)</span>, is sufficiently far from zero that we can be confident that <span class="math inline">\(\beta_1\)</span> is non-zero.
How far is enough?
This of course depends on the accuracy of <span class="math inline">\(\hat{\beta_1}\)</span>—that is, it depends on <span class="math inline">\(SE(\hat{\beta_1})\)</span>.
If <span class="math inline">\(SE(\hat{\beta_1})\)</span> is small, then even relatively small values of <span class="math inline">\(\hat{\beta_1}\)</span> may provide strong evidence that <span class="math inline">\(\beta_1 \neq 0\)</span>, and hence that there is a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
In contrast, if <span class="math inline">\(SE(\hat{\beta_1})\)</span> is large, then <span class="math inline">\(\hat{\beta_1}\)</span> must be large in absolute value in order for us to reject the null hypothesis.
In practice, we compute a <em>t-statistic</em>, give by</p>
<p><span class="math display" id="eq:t-stat">\[\begin{equation}
t = \frac{\hat{\beta_1}-0}{SE(\hat{\beta_1})} , \tag{3.14}
\end{equation}\]</span></p>
<p>which measures the number of standard deviations that <span class="math inline">\(\hat{\beta_1}\)</span> is away from 0.
If there really is no relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, then we expect that <a href="simple-lin-reg.html#eq:t-stat">(3.14)</a> will have a <em>t</em>-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom.
The t-distribution has a bell shape and for values of <em>n</em> greater than approximately 30 it is quite similar to the normal distribution.
Consequently, it is a simple matter to compute the probability of observing any number equal to <span class="math inline">\(|t|\)</span> or larger in absolute value, assuming <span class="math inline">\(\beta_1 = 0\)</span>.
We call this probability the <em>p-value</em>.
Roughly speaking, we interpret the p-value as follows: a small p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance, in the absence of any real association between the predictor and the response.
Hence, if we see a small p-value, then we can infer that there is an association between the predictor and the response.
We <em>reject the null hypothesis</em>—that is, we declare a relationship to exist between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>—if the p-value is amll enough.
Typical p-value cutoffs for rejecting the null hypothesis are 5 or 1%.
When <span class="math inline">\(n=30\)</span>, these correspond to t-statistics <a href="simple-lin-reg.html#eq:t-stat">(3.14)</a> of around 2 and 2.75, respectively.</p>
<p>{ Table 3.1 goes here }</p>
<p>Table 3.1 provides details of the least squares model for the regression of number of units sold on TV advertising budget for the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> data.
Notice that the coefficients for <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> are very large relative to their standard errors, so the t-statistics are also large; the probabilities of seeing such values if <span class="math inline">\(H_0\)</span> is true are virtually zero.
Hence we can conclude that <span class="math inline">\(\beta_0 \neq 0\)</span> and <span class="math inline">\(\beta_1 \neq 0\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</div>
<div id="assess-model-acc" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Assessing the Accuracy of the Model</h3>
<p>Once we have rejected the null hypothesis <a href="simple-lin-reg.html#eq:h-null">(3.12)</a> in favor of the alternative hypothesis <a href="simple-lin-reg.html#eq:h-a">(3.13)</a>, it is natural to want to quantify <em>the extent to which the model fits the data</em>.
The quality of a linear regression fit is typically assessed using two related quantities: the <em>residual standard error</em> and the <span class="math inline">\(R^2\)</span> statistic.</p>
<p>Table 3.2 displays the RSE, the <span class="math inline">\(R^2\)</span> statistic, and the F-statistic (to be described in Section 3.2.2) for the linear regression of number of units sold on TV advertising budget.</p>
<div id="residual-standard-error" class="section level4 unnumbered">
<h4>Residual Standard Error</h4>
<p>Recall from the model <a href="simple-lin-reg.html#eq:lin-rel">(3.5)</a> that associated with each observation is an error term <span class="math inline">\(\epsilon\)</span>.
Due to the presence of these error terms, even if we knew the true regression line (i.e. even if <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> were known), we would not be able to perfectly predict <span class="math inline">\(Y\)</span> from <span class="math inline">\(X\)</span>.
The RSE is an estimate of the standard deviation of <span class="math inline">\(\epsilon\)</span>.</p>
<p>{Table 3.2 goes here}</p>
<p>Roughly speaking, it is the average amount that the response will deviate from the true regression line.
It is computed using the formula</p>
<p><span class="math display" id="eq:rse">\[\begin{equation}
RSE = \sqrt{\frac{1}{n-2}RSS} = \sqrt{\frac{1}{n-2} \sum_{i=1}^{n} (y_i - \hat{y_i})^2} . \tag{3.15}
\end{equation}\]</span></p>
<p>Note that RSS was defined in Section 3.1.1, and is given by the formula</p>
<p><span class="math display" id="eq:rss-redefined">\[\begin{equation}
RSS = \sum_{i=1}^{n} (y_i - \hat{y_i})^2 . \tag{3.16}
\end{equation}\]</span></p>
<p>In the case of the advertising data, we see from the linear regression output in Table 3.2 that the RSE is 3.26.
In other words, actual sales in each market deviate from the true regression line by approximately 3,260 units, on average.
Another way to think about this is that even if the model were correct and the true values of the unknown coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> were known exactly, any prediction of sales on the basis of TV advertising would still be off by about 3,260 units on average.
Of course, whether or not 3,260 units is an acceptable prediction error depends on the problem context.
In the advertising data set, the mean value of <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> over all markets is approximately 14,000 units, and so the percentage error is <span class="math inline">\(3,260/14,000 = 23\%\)</span>.</p>
<p>The RSE is considered a measure of the <em>lack of fit</em> of the model <a href="simple-lin-reg.html#eq:lin-rel">(3.5)</a> to the data.
If the predictions obtained using the model are very close to the true outcome values—that is, if <span class="math inline">\(\hat{y_i} \approx y_i\)</span> for <span class="math inline">\(i = 1, ..., n\)</span>—then <a href="simple-lin-reg.html#eq:rse">(3.15)</a> will be small, and we can conclude that the model fits the data very well.
On the other hand, if <span class="math inline">\(\hat{y_i}\)</span> is very far from <span class="math inline">\(y_i\)</span> for one or more observations, then the RSE may be quite large, indicating that the model doesn’t fit the data well.</p>
</div>
<div id="r2-statistic" class="section level4 unnumbered">
<h4><em>R</em><sup>2</sup> Statistic</h4>
<p>The RSE provides an absolute measure of lack of fit of the model <a href="simple-lin-reg.html#eq:lin-rel">(3.5)</a> to the data.
But since it is measured in the units of <span class="math inline">\(Y\)</span>, it is not always clear what constitutes a good RSE.
The <span class="math inline">\(R^2\)</span> statistic provides an alternative measure of fit.
It takes the form of a <em>proportion</em>—the proportion of variance explained—and so it always takes on a value between 0 and 1, and is independent of the scale of <span class="math inline">\(Y\)</span>.</p>
<p>To calculate <span class="math inline">\(R^2\)</span>, we use the formula</p>
<p><span class="math display" id="eq:rsquared">\[\begin{equation}
R^2 = \frac{TSS-RSS}{TSS} = 1 - \frac{RSS}{TSS} \tag{3.17}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(TSS = \sum (y_i - \bar{y})^2\)</span> is the <em>total sum of squares</em>, and the RSS is defined in <a href="simple-lin-reg.html#eq:rss-redefined">(3.16)</a>.
TSS measures the total variance in the response <span class="math inline">\(Y\)</span>, and can be thought of as the amount of variability inherent in the response before the regression is performed.
In contrast, RSS measures the amount of variability that is left unexplained after performing the regression.
Hence, <span class="math inline">\(TSS - RSS\)</span> measures the amount of variability in the response that is explained (or removed) by performing the regression, and <span class="math inline">\(R^2\)</span> measures the <em>proportion of variability in Y that can be explained using X</em>.
An <span class="math inline">\(R^2\)</span> statistic that is close to 1 indicates that a large proportion of the variability in the response has been explained by the regression.
A number near 0 indicates that the regression did not explain much of the variability in the response; this might occur because the linear model is wrong, or the inherent error <span class="math inline">\(\sigma^2\)</span> is high, or both.
In Table 3.2, the <span class="math inline">\(R^2\)</span> was 0.61, and so just under two-thirds of the variability in <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> is explained by a linear regression on <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong>.</p>
<p>The <span class="math inline">\(R^2\)</span> statistic is a measure of the linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
Recall that <em>correlation</em>, defined as</p>
<p><span class="math display" id="eq:correlation">\[\begin{equation}
Cor(X,Y) = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2} \sqrt{\sum_{i=1}^{n} (y_i - \bar{y})^2}}, \tag{3.18}
\end{equation}\]</span></p>
<p>is also a measure of the linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>
This suggests that we might be able to use <span class="math inline">\(r = Cor(X,Y)\)</span> instead of <span class="math inline">\(R^2\)</span> in order to assess the fit of the linear model.
In fact, it can be shown that in the simple linear regression setting, <span class="math inline">\(R^2 = r^2\)</span>.
In other words, the squared correlation and the <span class="math inline">\(R^2\)</span> statistic are identical.
However, in the next section we will discuss the multiple linear regression problem, in which we use several predictors simultaneously to predict the response.
The concept of correlation between the predictors and the response does not extend automatically to this setting, since correlation quantifies the association between a single pair of variables rather than between a larger number of variables.
We will see that <span class="math inline">\(R^2\)</span> fills this role.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The assumption of linearity is often a useful working model.
However, despite what many textbooks might tell us, we seldom believe that the true relationship is linear.<a href="simple-lin-reg.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The formula holds provided that the <span class="math inline">\(n\)</span> observations are uncorrelated.<a href="simple-lin-reg.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p> <em>Approximately</em> for several reasons. Equation <a href="simple-lin-reg.html#eq:b1-interval">(3.10)</a> relies on the assumption that the errors are Guassian. Also, the factor of 2 in front of the <span class="math inline">\(SE(\hat{\beta_1})\)</span> term will vary slightly depending on the number of observations <em>n</em> in the linear regression.
To be precise, rather than the number 2, <a href="simple-lin-reg.html#eq:b1-interval">(3.10)</a> should contain the 97.5% quantile of a <em>t</em>-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom.
Details of how to compute the 95% confidence interval precisely in <code>R</code> will be preovided later in this chapter.<a href="simple-lin-reg.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>In Table 3.1, a small p-value for the intercept indicates that we can reject the null hpothesis that <span class="math inline">\(\beta_0 = 0\)</span>, and a small p-value for <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> indicates that we can reject the null hypothesis that <span class="math inline">\(\beta_1 = 0\)</span>.
Rejecting the latter null hypothesis allows us to conclude that there is a relationship between <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> and <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong>.
Rejecting the former allows us to conclude that in the absence of <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> expenditure, <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> are non-zero.<a href="simple-lin-reg.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>We should note that in fact, the right hand side of <a href="simple-lin-reg.html#eq:correlation">(3.18)</a> is the sample correlation; thus, it would be more correct to write <span class="math inline">\(\widehat{Cor(X,Y)}\)</span>; however, we omit the “hat” for ease of notation.<a href="simple-lin-reg.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linreg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mult-lin-reg.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BookdownISL.pdf", "BookdownISL.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
