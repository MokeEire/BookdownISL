<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.2 Multiple Linear Regression | An Introduction to Statistical Learning: with Applications in R</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="2.2 Multiple Linear Regression | An Introduction to Statistical Learning: with Applications in R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://faculty.marshall.usc.edu/gareth-james/ISL/" />
  <meta property="og:image" content="http://faculty.marshall.usc.edu/gareth-james/ISL/images/isl_cover.jpg" />
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="MokeEire/BookdownISL" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.2 Multiple Linear Regression | An Introduction to Statistical Learning: with Applications in R" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="twitter:image" content="http://faculty.marshall.usc.edu/gareth-james/ISL/images/isl_cover.jpg" />

<meta name="author" content="Gareth James, Daniela Witten, Trevor Hastie, &amp; Robert Tibshirani" />


<meta name="date" content="2020-12-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="simple-lin-reg.html"/>
<link rel="next" href="other-reg-cons.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/core-js-2.5.3/shim.min.js"></script>
<script src="libs/react-16.12.0/react.min.js"></script>
<script src="libs/react-16.12.0/react-dom.min.js"></script>
<script src="libs/reactwidget-1.0.0/react-tools.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/reactable-binding-0.2.3/reactable.js"></script>

<script>
/* ========================================================================
 * Bootstrap: transition.js v3.3.7
 * http://getbootstrap.com/javascript/#transitions
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // CSS TRANSITION SUPPORT (Shoutout: http://www.modernizr.com/)
  // ============================================================

  function transitionEnd() {
    var el = document.createElement('bootstrap')

    var transEndEventNames = {
      WebkitTransition : 'webkitTransitionEnd',
      MozTransition    : 'transitionend',
      OTransition      : 'oTransitionEnd otransitionend',
      transition       : 'transitionend'
    }

    for (var name in transEndEventNames) {
      if (el.style[name] !== undefined) {
        return { end: transEndEventNames[name] }
      }
    }

    return false // explicit for ie8 (  ._.)
  }

  // http://blog.alexmaccaw.com/css-transitions
  $.fn.emulateTransitionEnd = function (duration) {
    var called = false
    var $el = this
    $(this).one('bsTransitionEnd', function () { called = true })
    var callback = function () { if (!called) $($el).trigger($.support.transition.end) }
    setTimeout(callback, duration)
    return this
  }

  $(function () {
    $.support.transition = transitionEnd()

    if (!$.support.transition) return

    $.event.special.bsTransitionEnd = {
      bindType: $.support.transition.end,
      delegateType: $.support.transition.end,
      handle: function (e) {
        if ($(e.target).is(this)) return e.handleObj.handler.apply(this, arguments)
      }
    }
  })

}(jQuery);
</script>
<script>
/* ========================================================================
 * Bootstrap: collapse.js v3.3.7
 * http://getbootstrap.com/javascript/#collapse
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */

/* jshint latedef: false */

+function ($) {
  'use strict';

  // COLLAPSE PUBLIC CLASS DEFINITION
  // ================================

  var Collapse = function (element, options) {
    this.$element      = $(element)
    this.options       = $.extend({}, Collapse.DEFAULTS, options)
    this.$trigger      = $('[data-toggle="collapse"][href="#' + element.id + '"],' +
                           '[data-toggle="collapse"][data-target="#' + element.id + '"]')
    this.transitioning = null

    if (this.options.parent) {
      this.$parent = this.getParent()
    } else {
      this.addAriaAndCollapsedClass(this.$element, this.$trigger)
    }

    if (this.options.toggle) this.toggle()
  }

  Collapse.VERSION  = '3.3.7'

  Collapse.TRANSITION_DURATION = 350

  Collapse.DEFAULTS = {
    toggle: true
  }

  Collapse.prototype.dimension = function () {
    var hasWidth = this.$element.hasClass('width')
    return hasWidth ? 'width' : 'height'
  }

  Collapse.prototype.show = function () {
    if (this.transitioning || this.$element.hasClass('in')) return

    var activesData
    var actives = this.$parent && this.$parent.children('.panel').children('.in, .collapsing')

    if (actives && actives.length) {
      activesData = actives.data('bs.collapse')
      if (activesData && activesData.transitioning) return
    }

    var startEvent = $.Event('show.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    if (actives && actives.length) {
      Plugin.call(actives, 'hide')
      activesData || actives.data('bs.collapse', null)
    }

    var dimension = this.dimension()

    this.$element
      .removeClass('collapse')
      .addClass('collapsing')[dimension](0)
      .attr('aria-expanded', true)

    this.$trigger
      .removeClass('collapsed')
      .attr('aria-expanded', true)

    this.transitioning = 1

    var complete = function () {
      this.$element
        .removeClass('collapsing')
        .addClass('collapse in')[dimension]('')
      this.transitioning = 0
      this.$element
        .trigger('shown.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    var scrollSize = $.camelCase(['scroll', dimension].join('-'))

    this.$element
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)[dimension](this.$element[0][scrollSize])
  }

  Collapse.prototype.hide = function () {
    if (this.transitioning || !this.$element.hasClass('in')) return

    var startEvent = $.Event('hide.bs.collapse')
    this.$element.trigger(startEvent)
    if (startEvent.isDefaultPrevented()) return

    var dimension = this.dimension()

    this.$element[dimension](this.$element[dimension]())[0].offsetHeight

    this.$element
      .addClass('collapsing')
      .removeClass('collapse in')
      .attr('aria-expanded', false)

    this.$trigger
      .addClass('collapsed')
      .attr('aria-expanded', false)

    this.transitioning = 1

    var complete = function () {
      this.transitioning = 0
      this.$element
        .removeClass('collapsing')
        .addClass('collapse')
        .trigger('hidden.bs.collapse')
    }

    if (!$.support.transition) return complete.call(this)

    this.$element
      [dimension](0)
      .one('bsTransitionEnd', $.proxy(complete, this))
      .emulateTransitionEnd(Collapse.TRANSITION_DURATION)
  }

  Collapse.prototype.toggle = function () {
    this[this.$element.hasClass('in') ? 'hide' : 'show']()
  }

  Collapse.prototype.getParent = function () {
    return $(this.options.parent)
      .find('[data-toggle="collapse"][data-parent="' + this.options.parent + '"]')
      .each($.proxy(function (i, element) {
        var $element = $(element)
        this.addAriaAndCollapsedClass(getTargetFromTrigger($element), $element)
      }, this))
      .end()
  }

  Collapse.prototype.addAriaAndCollapsedClass = function ($element, $trigger) {
    var isOpen = $element.hasClass('in')

    $element.attr('aria-expanded', isOpen)
    $trigger
      .toggleClass('collapsed', !isOpen)
      .attr('aria-expanded', isOpen)
  }

  function getTargetFromTrigger($trigger) {
    var href
    var target = $trigger.attr('data-target')
      || (href = $trigger.attr('href')) && href.replace(/.*(?=#[^\s]+$)/, '') // strip for ie7

    return $(target)
  }


  // COLLAPSE PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this   = $(this)
      var data    = $this.data('bs.collapse')
      var options = $.extend({}, Collapse.DEFAULTS, $this.data(), typeof option == 'object' && option)

      if (!data && options.toggle && /show|hide/.test(option)) options.toggle = false
      if (!data) $this.data('bs.collapse', (data = new Collapse(this, options)))
      if (typeof option == 'string') data[option]()
    })
  }

  var old = $.fn.collapse

  $.fn.collapse             = Plugin
  $.fn.collapse.Constructor = Collapse


  // COLLAPSE NO CONFLICT
  // ====================

  $.fn.collapse.noConflict = function () {
    $.fn.collapse = old
    return this
  }


  // COLLAPSE DATA-API
  // =================

  $(document).on('click.bs.collapse.data-api', '[data-toggle="collapse"]', function (e) {
    var $this   = $(this)

    if (!$this.attr('data-target')) e.preventDefault()

    var $target = getTargetFromTrigger($this)
    var data    = $target.data('bs.collapse')
    var option  = data ? 'toggle' : $this.data()

    Plugin.call($target, option)
  })

}(jQuery);
</script>
<script>
window.initializeCodeFolding = function(show) {

  // handlers for show-all and hide all
  $("#rmd-show-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('show');
    });
  });
  $("#rmd-hide-all-code").click(function() {
    // close the dropdown menu when an option is clicked
    $("#allCodeButton").dropdown("toggle");
    $('div.r-code-collapse').each(function() {
      $(this).collapse('hide');
    });
  });

  // index for unique code element ids
  var currentIndex = 1;

  // select all R code blocks
  var rCodeBlocks = $('pre.sourceCode, pre.r, pre.python, pre.bash, pre.sql, pre.cpp, pre.stan');
  rCodeBlocks.each(function() {

    // create a collapsable div to wrap the code in
    var div = $('<div class="collapse r-code-collapse"></div>');
    if (show)
      div.addClass('in');
    var id = 'rcode-643E0F36' + currentIndex++;
    div.attr('id', id);
    $(this).before(div);
    $(this).detach().appendTo(div);

    // add a show code button right above
    var showCodeText = $('<span>' + (show ? 'Hide' : 'Code') + '</span>');
    var showCodeButton = $('<button type="button" class="btn btn-default btn-xs code-folding-btn pull-right"></button>');
    showCodeButton.append(showCodeText);
    showCodeButton
        .attr('data-toggle', 'collapse')
        .attr('data-target', '#' + id)
        .attr('aria-expanded', show)
        .attr('aria-controls', id);

    var buttonRow = $('<div class="row"></div>');
    var buttonCol = $('<div class="col-md-12"></div>');

    buttonCol.append(showCodeButton);
    buttonRow.append(buttonCol);

    div.before(buttonRow);

    // update state of button on show/hide
    div.on('hidden.bs.collapse', function () {
      showCodeText.text('Code');
    });
    div.on('show.bs.collapse', function () {
      showCodeText.text('Hide');
    });
  });

}
</script>
<script>
/* ========================================================================
 * Bootstrap: dropdown.js v3.3.7
 * http://getbootstrap.com/javascript/#dropdowns
 * ========================================================================
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 * ======================================================================== */


+function ($) {
  'use strict';

  // DROPDOWN CLASS DEFINITION
  // =========================

  var backdrop = '.dropdown-backdrop'
  var toggle   = '[data-toggle="dropdown"]'
  var Dropdown = function (element) {
    $(element).on('click.bs.dropdown', this.toggle)
  }

  Dropdown.VERSION = '3.3.7'

  function getParent($this) {
    var selector = $this.attr('data-target')

    if (!selector) {
      selector = $this.attr('href')
      selector = selector && /#[A-Za-z]/.test(selector) && selector.replace(/.*(?=#[^\s]*$)/, '') // strip for ie7
    }

    var $parent = selector && $(selector)

    return $parent && $parent.length ? $parent : $this.parent()
  }

  function clearMenus(e) {
    if (e && e.which === 3) return
    $(backdrop).remove()
    $(toggle).each(function () {
      var $this         = $(this)
      var $parent       = getParent($this)
      var relatedTarget = { relatedTarget: this }

      if (!$parent.hasClass('open')) return

      if (e && e.type == 'click' && /input|textarea/i.test(e.target.tagName) && $.contains($parent[0], e.target)) return

      $parent.trigger(e = $.Event('hide.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this.attr('aria-expanded', 'false')
      $parent.removeClass('open').trigger($.Event('hidden.bs.dropdown', relatedTarget))
    })
  }

  Dropdown.prototype.toggle = function (e) {
    var $this = $(this)

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    clearMenus()

    if (!isActive) {
      if ('ontouchstart' in document.documentElement && !$parent.closest('.navbar-nav').length) {
        // if mobile we use a backdrop because click events don't delegate
        $(document.createElement('div'))
          .addClass('dropdown-backdrop')
          .insertAfter($(this))
          .on('click', clearMenus)
      }

      var relatedTarget = { relatedTarget: this }
      $parent.trigger(e = $.Event('show.bs.dropdown', relatedTarget))

      if (e.isDefaultPrevented()) return

      $this
        .trigger('focus')
        .attr('aria-expanded', 'true')

      $parent
        .toggleClass('open')
        .trigger($.Event('shown.bs.dropdown', relatedTarget))
    }

    return false
  }

  Dropdown.prototype.keydown = function (e) {
    if (!/(38|40|27|32)/.test(e.which) || /input|textarea/i.test(e.target.tagName)) return

    var $this = $(this)

    e.preventDefault()
    e.stopPropagation()

    if ($this.is('.disabled, :disabled')) return

    var $parent  = getParent($this)
    var isActive = $parent.hasClass('open')

    if (!isActive && e.which != 27 || isActive && e.which == 27) {
      if (e.which == 27) $parent.find(toggle).trigger('focus')
      return $this.trigger('click')
    }

    var desc = ' li:not(.disabled):visible a'
    var $items = $parent.find('.dropdown-menu' + desc)

    if (!$items.length) return

    var index = $items.index(e.target)

    if (e.which == 38 && index > 0)                 index--         // up
    if (e.which == 40 && index < $items.length - 1) index++         // down
    if (!~index)                                    index = 0

    $items.eq(index).trigger('focus')
  }


  // DROPDOWN PLUGIN DEFINITION
  // ==========================

  function Plugin(option) {
    return this.each(function () {
      var $this = $(this)
      var data  = $this.data('bs.dropdown')

      if (!data) $this.data('bs.dropdown', (data = new Dropdown(this)))
      if (typeof option == 'string') data[option].call($this)
    })
  }

  var old = $.fn.dropdown

  $.fn.dropdown             = Plugin
  $.fn.dropdown.Constructor = Dropdown


  // DROPDOWN NO CONFLICT
  // ====================

  $.fn.dropdown.noConflict = function () {
    $.fn.dropdown = old
    return this
  }


  // APPLY TO STANDARD DROPDOWN ELEMENTS
  // ===================================

  $(document)
    .on('click.bs.dropdown.data-api', clearMenus)
    .on('click.bs.dropdown.data-api', '.dropdown form', function (e) { e.stopPropagation() })
    .on('click.bs.dropdown.data-api', toggle, Dropdown.prototype.toggle)
    .on('keydown.bs.dropdown.data-api', toggle, Dropdown.prototype.keydown)
    .on('keydown.bs.dropdown.data-api', '.dropdown-menu', Dropdown.prototype.keydown)

}(jQuery);
</script>
<style type="text/css">
.code-folding-btn {
  margin-bottom: 4px;
}

.row { display: flex; }
.collapse { display: none; }
.in { display:block }
.pull-right > .dropdown-menu {
    right: 0;
    left: auto;
}

.dropdown-menu {
    position: absolute;
    top: 100%;
    left: 0;
    z-index: 1000;
    display: none;
    float: left;
    min-width: 160px;
    padding: 5px 0;
    margin: 2px 0 0;
    font-size: 14px;
    text-align: left;
    list-style: none;
    background-color: #fff;
    -webkit-background-clip: padding-box;
    background-clip: padding-box;
    border: 1px solid #ccc;
    border: 1px solid rgba(0,0,0,.15);
    border-radius: 4px;
    -webkit-box-shadow: 0 6px 12px rgba(0,0,0,.175);
    box-shadow: 0 6px 12px rgba(0,0,0,.175);
}

.open > .dropdown-menu {
    display: block;
    color: #ffffff;
    background-color: #ffffff;
    background-image: none;
    border-color: #92897e;
}

.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: 400;
  line-height: 1.42857143;
  color: #000000;
  white-space: nowrap;
}

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
}

.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #ffffff;
  text-decoration: none;
  background-color: #e95420;
  outline: 0;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #aea79f;
}

.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  cursor: not-allowed;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}

.btn {
  display: inline-block;
  margin-bottom: 1;
  font-weight: normal;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  -ms-touch-action: manipulation;
      touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  padding: 4px 8px;
  font-size: 14px;
  line-height: 1.42857143;
  border-radius: 4px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #ffffff;
  text-decoration: none;
}
.btn:active,
.btn.active {
  background-image: none;
  outline: 0;
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  filter: alpha(opacity=65);
  opacity: 0.65;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #ffffff;
  background-color: #aea79f; #important
  border-color: #aea79f;
}

.btn-default:focus,
.btn-default.focus {
  color: #ffffff;
  background-color: #978e83;
  border-color: #6f675e;
}

.btn-default:hover {
  color: #ffffff;
  background-color: #978e83;
  border-color: #92897e;
}
.btn-default:active,
.btn-default.active,
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-top-right-radius: 0;
  border-bottom-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-left-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-right: 8px;
  padding-left: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-right: 12px;
  padding-left: 12px;
}
.btn-group.open .dropdown-toggle {
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  box-shadow: none;
}

</style>
<script>
var str = '<div class="btn-group pull-right" style="position: fixed; right: 50px; top: 10px; z-index: 200"><button type="button" class="btn btn-default btn-xs dropdown-toggle" id="allCodeButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" data-_extension-text-contrast=""><span>Code</span> <span class="caret"></span></button><ul class="dropdown-menu" style="min-width: 50px;"><li><a id="rmd-show-all-code" href="#">Show All Code</a></li><li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li></ul></div>';
document.write(str);
</script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "hide");
});
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="http://faculty.marshall.usc.edu/gareth-james/ISL/" target="blank">An Introduction to Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="resources-used-in-making-this-book.html"><a href="resources-used-in-making-this-book.html"><i class="fa fa-check"></i>Resources used in making this book</a></li>
<li class="chapter" data-level="" data-path="custom-functions-used-throughout-the-book.html"><a href="custom-functions-used-throughout-the-book.html"><i class="fa fa-check"></i>Custom functions used throughout the book</a><ul>
<li><a href="custom-functions-used-throughout-the-book.html#theme_islr"><code>theme_islr()</code></a></li>
<li><a href="custom-functions-used-throughout-the-book.html#prep_reg_table"><code>prep_reg_table()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="an-overview-of-statistical-learning.html"><a href="an-overview-of-statistical-learning.html"><i class="fa fa-check"></i><b>1.1</b> An Overview of Statistical Learning</a><ul>
<li class="chapter" data-level="1.1.1" data-path="an-overview-of-statistical-learning.html"><a href="an-overview-of-statistical-learning.html#wage-data"><i class="fa fa-check"></i><b>1.1.1</b> Wage Data</a></li>
<li class="chapter" data-level="1.1.2" data-path="an-overview-of-statistical-learning.html"><a href="an-overview-of-statistical-learning.html#stock-market-data"><i class="fa fa-check"></i><b>1.1.2</b> Stock Market Data</a></li>
<li class="chapter" data-level="1.1.3" data-path="an-overview-of-statistical-learning.html"><a href="an-overview-of-statistical-learning.html#gene-expression-data"><i class="fa fa-check"></i><b>1.1.3</b> Gene Expression Data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="a-brief-history-of-statistical-learning.html"><a href="a-brief-history-of-statistical-learning.html"><i class="fa fa-check"></i><b>1.2</b> A Brief History of Statistical Learning</a></li>
<li class="chapter" data-level="1.3" data-path="this-book.html"><a href="this-book.html"><i class="fa fa-check"></i><b>1.3</b> This Book</a></li>
<li class="chapter" data-level="1.4" data-path="who-should-read-this-book.html"><a href="who-should-read-this-book.html"><i class="fa fa-check"></i><b>1.4</b> Who Should Read This Book</a></li>
<li class="chapter" data-level="1.5" data-path="notation-and-simple-matrix-algebra.html"><a href="notation-and-simple-matrix-algebra.html"><i class="fa fa-check"></i><b>1.5</b> Notation and Simple Matrix Algebra</a></li>
<li class="chapter" data-level="1.6" data-path="organization-of-this-book.html"><a href="organization-of-this-book.html"><i class="fa fa-check"></i><b>1.6</b> Organization of This Book</a></li>
<li class="chapter" data-level="1.7" data-path="data-sets-used-in-labs-and-exercises.html"><a href="data-sets-used-in-labs-and-exercises.html"><i class="fa fa-check"></i><b>1.7</b> Data Sets Used in Labs and Exercises</a></li>
<li class="chapter" data-level="1.8" data-path="book-website.html"><a href="book-website.html"><i class="fa fa-check"></i><b>1.8</b> Book Website</a></li>
<li class="chapter" data-level="1.9" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>2</b> Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html"><i class="fa fa-check"></i><b>2.1</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="2.1.1" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#simple-coef-est"><i class="fa fa-check"></i><b>2.1.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#assess-coef-acc"><i class="fa fa-check"></i><b>2.1.2</b> Assessing the Accuracy of the Coefficient Estimates</a></li>
<li class="chapter" data-level="2.1.3" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#assess-model-acc"><i class="fa fa-check"></i><b>2.1.3</b> Assessing the Accuracy of the Model</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="mult-lin-reg.html"><a href="mult-lin-reg.html"><i class="fa fa-check"></i><b>2.2</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="2.2.1" data-path="mult-lin-reg.html"><a href="mult-lin-reg.html#est-reg-coef"><i class="fa fa-check"></i><b>2.2.1</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="2.2.2" data-path="mult-lin-reg.html"><a href="mult-lin-reg.html#important-questions"><i class="fa fa-check"></i><b>2.2.2</b> Some Important Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="other-reg-cons.html"><a href="other-reg-cons.html"><i class="fa fa-check"></i><b>2.3</b> Other Considerations in the Regression Model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="other-reg-cons.html"><a href="other-reg-cons.html#qualitative-predictors"><i class="fa fa-check"></i><b>2.3.1</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="2.3.2" data-path="other-reg-cons.html"><a href="other-reg-cons.html#extensions-of-the-linear-model"><i class="fa fa-check"></i><b>2.3.2</b> Extensions of the Linear Model</a></li>
<li class="chapter" data-level="2.3.3" data-path="other-reg-cons.html"><a href="other-reg-cons.html#potential-problems"><i class="fa fa-check"></i><b>2.3.3</b> Potential Problems</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="the-marketing-plan.html"><a href="the-marketing-plan.html"><i class="fa fa-check"></i><b>2.4</b> The Marketing Plan</a></li>
<li class="chapter" data-level="2.5" data-path="comparison-of-linear-regression-with-k-nearest-neighbors.html"><a href="comparison-of-linear-regression-with-k-nearest-neighbors.html"><i class="fa fa-check"></i><b>2.5</b> Comparison of Linear Regression with K-Nearest Neighbors</a></li>
<li class="chapter" data-level="2.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html"><i class="fa fa-check"></i><b>2.6</b> Lab: Linear Regression</a><ul>
<li class="chapter" data-level="2.6.1" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#libraries"><i class="fa fa-check"></i><b>2.6.1</b> Libraries</a></li>
<li class="chapter" data-level="2.6.2" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>2.6.2</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="2.6.3" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>2.6.3</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="2.6.4" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#interaction-terms"><i class="fa fa-check"></i><b>2.6.4</b> Interaction Terms</a></li>
<li class="chapter" data-level="2.6.5" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#non-linear-transformations-of-the-predictors"><i class="fa fa-check"></i><b>2.6.5</b> Non-linear Transformations of the Predictors</a></li>
<li class="chapter" data-level="2.6.6" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#qualitative-predictors-1"><i class="fa fa-check"></i><b>2.6.6</b> Qualitative Predictors</a></li>
<li class="chapter" data-level="2.6.7" data-path="lab-linear-regression.html"><a href="lab-linear-regression.html#writing-functions"><i class="fa fa-check"></i><b>2.6.7</b> Writing Functions</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.7</b> Exercises</a><ul>
<li class="chapter" data-level="2.7.1" data-path="exercises.html"><a href="exercises.html#conceptual"><i class="fa fa-check"></i><b>2.7.1</b> Conceptual</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning: with Applications in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mult-lin-reg" class="section level2">
<h2><span class="header-section-number">2.2</span> Multiple Linear Regression</h2>
<p>Simple linear regression is a useful approach for predicting a response on the basis of a single predictor variable.
However, in practice we often have more than one predictor.
For example, in the <code>Advertising</code> data, we have examined the relationship between sales and TV advertising.
We also have data for the amount of money spent on advertising on the radio and in newspapers, and we may want to know whether either of these two media is associated with sales.
How can we extend our analysis of the advertising data in order to accommodate these two additional predictors?</p>
<p>One option is to run three separate simple linear regressions, each of which uses a different advertising medium as a predictor.
For instance, we can fit a simple linear regression to predict sales on the basis of the amount spent on radio advertisements.
Results are shown in Table 3.3 (top table).
We find that a $1,000 increase in spending on radio advertising is associated with an increase in sales by around 203 units.
Table 3.3 (bottom table) contains the least squares coefficients for a simple linear regression of sales onto newspaper advertising budget.
A $1,000 increase in newspaper advertising budget is associated with an increase in sales by approximately 55 units.</p>
<p>However, the approach of fitting a separate simple linear regression model for each predictor is not entirely satisfactory.
First of all, it is unclear how to make a single prediction of sales given levels of the three advertising media budgets, since each of the budgets is associated with a separate regression equation.
Second, each of the three regression equations ignores the other two media in forming estimates for the regression coefficients.
We will see shortly that if the media budgets are correlated with each other in the 200 markets that constitute our data set, then this can lead to very misleading estimates of the individual media effects on sales.</p>
<p>Instead of fitting a separate simple linear regression model for each predictor, a better approach is to extend the simple linear regression model <a href="simple-lin-reg.html#eq:lin-rel">(2.5)</a> so that it can directly accommodate multiple predictors.
We can do this by giving each predictor a separate slope coefficient in a single model.
In general, suppose that we have <em>p</em> distinct predictors.
Then the multiple linear regression model takes the form</p>
<p><span class="math display" id="eq:mlin-reg">\[\begin{equation}
  Y = \beta_0+\beta_1X_1 +\beta_2X_2 + ... +\beta_pX_p + \epsilon,
  \tag{2.19}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(X_j\)</span> represents the <em>j</em>th predictor and <span class="math inline">\(\beta_j\)</span> quantifies the association between that variable and the response.
We interpret <span class="math inline">\(\beta_j\)</span> as the <em>average</em> effect on <span class="math inline">\(Y\)</span> of a one unit increase in <span class="math inline">\(X_j\)</span>, <em>holding all other predictors fixed</em>.
In the advertising example, <a href="mult-lin-reg.html#eq:mlin-reg">(2.19)</a> becomes</p>
<p><span class="math display" id="eq:mlin-reg-adv">\[\begin{equation}
  \color{#B44C1C}{\textbf{sales}} = \beta_0 + \beta_1 \times \color{#B44C1C}{\textbf{TV}}+\beta_2 \times \color{#B44C1C}{\textbf{radio}}+\beta_3 \times \color{#B44C1C}{\textbf{newspaper}}+ \epsilon. \tag{2.20}
\end{equation}\]</span></p>
<div id="est-reg-coef" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Estimating the Regression Coefficients</h3>
<p>As was the case in the simple linear regression setting, the regression coefficients <span class="math inline">\(\beta_0, \beta_1, ..., \beta_p\)</span> in <a href="mult-lin-reg.html#eq:mlin-reg">(2.19)</a> are unknown, and must be estimated.
Given estimates <span class="math inline">\(\hat{\beta_0}, \hat{\beta_1}, ..., \hat{\beta_p}\)</span>, we can make predictions using the formula</p>
<p><span class="math display" id="eq:mlin-reg-est">\[\begin{equation}
  \hat{y} = \hat{\beta_0}+\hat{\beta_1}x_1 +\hat{\beta_2}x_2 + ... +\hat{\beta_p}x_p + \epsilon,
  \tag{2.21}
\end{equation}\]</span></p>
<p>The parameters are estimated using the same least squares approach that we saw in the context of simple linear regression.
We choose <span class="math inline">\(\beta_0, \beta_1, ..., \beta_p\)</span> to minimize the sum of squared residuals</p>
<p><span class="math display" id="eq:m-rssmin">\[\begin{equation} 
\begin{aligned}
  RSS &amp;= \sum_{i=1}^{n} (y_i-\hat{y})^2 \\
      &amp;= \sum_{i=1}^{n} (y_i-\hat{\beta_0} - \hat{\beta_1}x_{i1} - \hat{\beta_2}x_{i2} - ... - \hat{\beta_p}x_{ip})^2.
  \end{aligned}
  \tag{2.22}
\end{equation}\]</span></p>
<p>The values <span class="math inline">\(\hat{\beta_0}, \hat{\beta_1}, ..., \hat{\beta_p}\)</span> that minimize <a href="mult-lin-reg.html#eq:m-rssmin">(2.22)</a> are the multiple least squares regression coefficient estimates.
Unlike the simple linear regression estimates given in <a href="simple-lin-reg.html#eq:rssmin">(2.4)</a>, the multiple regression coefficient estimates have somewhat complicated forms that are most easily represented using matrix algebra.
For this reason, we do not provide them here.
Any statistical software package can be used to compute these coefficient estimates, and later in this chapter we will show how this can be done in <code>R</code>.
Figure 3.4 illustrates an example of the least squares fit to a toy data set with <span class="math inline">\(p = 2\)</span> predictors.</p>
<p>Table 3.4 displays the multiple regression coefficient estimates when TV, radio, and advertising budgets are used to predict product sales using the <code>Advertising</code> data.
We interpret these results as follows: for a given amount of TV and newspaper advertising, spending an additional $1,000 on radio advertising leads to an increase in sales by approximately 189 units.
Comparing these coefficient estimates to those displayed in Table 3.1 and 3.3, we notice that the multiple regression coefficient estimates for <code>TV</code> and <code>radio</code> are pretty similar to the simple linear regression coefficient estimates.
However, while the <code>newspaper</code> regression coefficient estimate in Table 3.3 was significantly non-zero, the coefficient estimate for <code>newspaper</code> in the multiple regression model is close to zero, and the corresponding p-value is no longer significant, with a value around 0.86.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="mult-lin-reg.html#cb5-1"></a><span class="co"># estimate linear model</span></span>
<span id="cb5-2"><a href="mult-lin-reg.html#cb5-2"></a>advertising_mlin_reg =<span class="st"> </span><span class="kw">lm</span>(sales<span class="op">~</span>TV<span class="op">+</span>radio<span class="op">+</span>newspaper, <span class="dt">data =</span> advertising)</span>
<span id="cb5-3"><a href="mult-lin-reg.html#cb5-3"></a></span>
<span id="cb5-4"><a href="mult-lin-reg.html#cb5-4"></a><span class="co"># Clean up the model output</span></span>
<span id="cb5-5"><a href="mult-lin-reg.html#cb5-5"></a><span class="kw">prep_reg_table</span>(advertising_mlin_reg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb5-6"><a href="mult-lin-reg.html#cb5-6"></a><span class="st">  </span><span class="co"># use reactable to produce the table</span></span>
<span id="cb5-7"><a href="mult-lin-reg.html#cb5-7"></a><span class="st">  </span><span class="kw">reactable</span>(</span>
<span id="cb5-8"><a href="mult-lin-reg.html#cb5-8"></a>    <span class="dt">borderless =</span> T,</span>
<span id="cb5-9"><a href="mult-lin-reg.html#cb5-9"></a>    <span class="dt">sortable =</span> F,</span>
<span id="cb5-10"><a href="mult-lin-reg.html#cb5-10"></a>    <span class="dt">defaultColDef =</span> <span class="kw">colDef</span>(<span class="dt">format =</span> <span class="kw">colFormat</span>(<span class="dt">digits =</span> <span class="dv">3</span>)),</span>
<span id="cb5-11"><a href="mult-lin-reg.html#cb5-11"></a>    <span class="co"># Specific column formats</span></span>
<span id="cb5-12"><a href="mult-lin-reg.html#cb5-12"></a>    <span class="dt">columns =</span> <span class="kw">list</span>(</span>
<span id="cb5-13"><a href="mult-lin-reg.html#cb5-13"></a>      <span class="dt">term =</span> <span class="kw">colDef</span>(</span>
<span id="cb5-14"><a href="mult-lin-reg.html#cb5-14"></a>        <span class="dt">name =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb5-15"><a href="mult-lin-reg.html#cb5-15"></a>        <span class="dt">style =</span> <span class="kw">list</span>(<span class="dt">borderRight =</span> <span class="st">&quot;2px solid black&quot;</span>,</span>
<span id="cb5-16"><a href="mult-lin-reg.html#cb5-16"></a>                                 <span class="dt">color =</span> <span class="st">&quot;#B44C1C&quot;</span>,</span>
<span id="cb5-17"><a href="mult-lin-reg.html#cb5-17"></a>                                 <span class="dt">fontFamily =</span> <span class="st">&quot;Roboto Mono&quot;</span>),</span>
<span id="cb5-18"><a href="mult-lin-reg.html#cb5-18"></a>        <span class="dt">headerStyle =</span> <span class="kw">list</span>(<span class="dt">borderRight =</span> <span class="st">&quot;2px solid black&quot;</span>)),</span>
<span id="cb5-19"><a href="mult-lin-reg.html#cb5-19"></a>      <span class="st">`</span><span class="dt">t-statistic</span><span class="st">`</span> =<span class="st"> </span><span class="kw">colDef</span>(<span class="dt">format =</span> <span class="kw">colFormat</span>(<span class="dt">digits =</span> <span class="dv">2</span>))</span>
<span id="cb5-20"><a href="mult-lin-reg.html#cb5-20"></a>    )</span>
<span id="cb5-21"><a href="mult-lin-reg.html#cb5-21"></a>  )</span>
<span id="cb5-22"><a href="mult-lin-reg.html#cb5-22"></a></span>
<span id="cb5-23"><a href="mult-lin-reg.html#cb5-23"></a><span class="co"># Put the caption beneath the table</span></span>
<span id="cb5-24"><a href="mult-lin-reg.html#cb5-24"></a><span class="kw">rt_caption</span>(</span>
<span id="cb5-25"><a href="mult-lin-reg.html#cb5-25"></a>  <span class="dt">text =</span> <span class="kw">str_c</span>(<span class="st">&quot;For the &quot;</span>, <span class="kw">data_colour</span>(<span class="st">&quot;Advertising&quot;</span>), <span class="st">&quot; data, least squares coefficient estimates of the multiple linear regression of number of units sold on radio, TV, and newspaper advertising budgets.&quot;</span>), </span>
<span id="cb5-26"><a href="mult-lin-reg.html#cb5-26"></a>  <span class="dt">tab_num =</span> <span class="fl">3.4</span></span>
<span id="cb5-27"><a href="mult-lin-reg.html#cb5-27"></a>  )</span></code></pre></div>
<p><div id="htmlwidget-d5f5b9dd9b2492fe3b9c" class="reactable html-widget" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-d5f5b9dd9b2492fe3b9c">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"term":["Intercept","TV","radio","newspaper"],"Coefficient":[2.93888936945942,0.0457646454553976,0.188530016918204,-0.00103749304247626],"Std. Error":[0.311908236321791,0.00139489680697498,0.00861123396730194,0.00587100964708637],"t-statistic":[9.42228844007638,32.8086244276697,21.8934960580654,-0.176714586560276],"p-value":["<0.0001","<0.0001","<0.0001","0.8599"]},"columns":[{"accessor":"term","name":"","type":"character","format":{"cell":{"digits":3},"aggregated":{"digits":3}},"style":{"borderRight":"2px solid black","color":"#B44C1C","fontFamily":"Roboto Mono"},"headerStyle":{"borderRight":"2px solid black"}},{"accessor":"Coefficient","name":"Coefficient","type":"numeric","format":{"cell":{"digits":3},"aggregated":{"digits":3}}},{"accessor":"Std. Error","name":"Std. Error","type":"numeric","format":{"cell":{"digits":3},"aggregated":{"digits":3}}},{"accessor":"t-statistic","name":"t-statistic","type":"numeric","format":{"cell":{"digits":2},"aggregated":{"digits":2}}},{"accessor":"p-value","name":"p-value","type":"character","format":{"cell":{"digits":3},"aggregated":{"digits":3}}}],"sortable":false,"defaultPageSize":10,"paginationType":"numbers","showPageInfo":true,"minRows":1,"borderless":true,"theme":{"color":"#333","tableStyle":{"borderTop":"2px solid black","borderBottom":"2px solid black"},"headerStyle":{"borderBottom":"2px solid black"}},"dataKey":"5f2607354a493267c6d0fb92eee9decb","key":"5f2607354a493267c6d0fb92eee9decb"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script><div class="rt-caption">
<span class="tab-num">TABLE 3.4.</span>
<em>For the <strong><span style='font-family:monospace; color: #B44C1C;'>Advertising</span></strong> data, least squares coefficient estimates of the multiple linear regression of number of units sold on radio, TV, and newspaper advertising budgets.</em>
</div></p>
<p>This illustrates that the simple and multiple regression coefficients can be quite different.
This difference stems from the fact that in the simple regression case, the slope term represents the average effect of a $1,000 increase in newspaper advertising, ignoring other predictors such as <code>TV</code> and <code>radio</code>.
In contrast, in the multiple regression setting, the coefficient for <code>newspaper</code> represents the average effect of increasing newspaper spending by $1,000 while holding <code>TV</code> and <code>radio</code> fixed.</p>
<p>Does it make sense for the multiple regression to suggest no relationship between <code>sales</code> and <code>newspaper</code> while the simple linear regression implies the opposite?
In fact it does.
Consider the correlation matrix for the three predictor variables and response variable, displayed in Table 3.5.
Notice that the correlation between <code>radio</code> and <code>newspaper</code> is 0.35.
This reveals a tendency to spend more on newspaper advertising in markets where more is spent on radio advertising.
Now suppose that the multiple regression is correct and newspaper advertising has no direct impact on sales, but radio advertising does increase sales.
Then in markets where we spend more on radio our sales will tend to be higher, and as our correlation matrix shows, we also tend to spend more on newspaper advertising in those same markets.
Hence, in a simple linear regression which only examines <code>sales</code> versus <code>newspaper</code>, we will observe that higher values of <code>newspaper</code> tend to be associated with higher values of <code>sales</code>, even though newspaper advertising does not actually affect sales.
So <code>newspaper</code> sales are a surrogate for <code>radio</code> advertising; newspaper gets “credit” for the effect of <code>radio</code> on <code>sales</code>.</p>
<p>This slightly counterintuitive result is very common in many real life situations.
Consider an absurd example to illustrate the point.
Running a regression of shark attacks versus ice cream sales for data collected at a given beach community over a period of time would show a positive relationship, similar to that seen between <code>sales</code> and <code>newspaper</code>.
Of course no one (yet) has suggested that ice creams should be banned at beaches to reduce shark attacks.
In reality, higher temperatures cause more people to visit the beach, which in turn results in more ice cream sales and more shark attacks.
A multiple regression of attacks versus ice cream sales and temperature reveals that, as intuition implies, the former predictor is no longer significant after adjusting for temperature.</p>
</div>
<div id="important-questions" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Some Important Questions</h3>
<p>When we perform multiple linear regression, we usually are interested in answering a few important questions.</p>
<ol style="list-style-type: decimal">
<li><p><em>Is at least one of the predictors <span class="math inline">\(X_1 , X_2 , ... , X_p\)</span> useful in predicting the response?</em></p></li>
<li><p><em>Do all the predictors help to explain <span class="math inline">\(Y\)</span>, or is only a subset of the predictors useful?</em></p></li>
<li><p><em>How well does the model fit the data?</em></p></li>
<li><p><em>Given a set of predictor values, what response value should we predict, and how accurate is our prediction?</em></p></li>
</ol>
<p>We now address each of these questions in turn.</p>
<div id="one-is-there-a-relationship-between-the-response-and-predictors" class="section level4">
<h4><span class="header-section-number">2.2.2.1</span> One: Is There a Relationship Between the Response and Predictors?</h4>
<p>Recall that in the simple linear regression setting, in order to determine whether there is a relationship between the response and the predictor we can simply check whether <span class="math inline">\(\beta_1 = 0\)</span>.
In the multiple regression setting with <span class="math inline">\(p\)</span> predictors, we need to ask whether all of the regression coefficients are zero, i.e. whether <span class="math inline">\(\beta_1 = \beta_2 = ... = \beta_p = 0\)</span>.
As in the simple linear regression setting, we use a hypothesis test to answer this question.
We test the null hypothesis,</p>
<p><span class="math display">\[H_0: \beta_1 = \beta_2 = ... = \beta_p = 0\]</span></p>
<p>versus the alternative</p>
<p><span class="math display">\[H_a: \mathrm{at\ least\ one\ \beta_j\ is\ non-zero}\]</span></p>
<p>This hypothesis test is performed by computing the <strong><span style="font-family:monospace; color: #1188ce;">F-statistic</span></strong>,</p>
<p><span class="math display" id="eq:fstat">\[\begin{equation}
  F = \frac{(TSS-RSS)/p}{RSS/(n-p-1)},
  \tag{2.23}
\end{equation}\]</span></p>
<p>where, as with simple linear regression, <span class="math inline">\(TSS = \sum{(y_i - \bar{y})^2}\)</span> and <span class="math inline">\(RSS = \sum{(y_i - \hat{y_i})^2}\)</span>.
If the linear model assumptions are correct, one can show that</p>
<p><span class="math display">\[ E\{RSS/(n-p-1)\} = \sigma^2 \]</span></p>
<p>and that, provided <span class="math inline">\(H_0\)</span> is true.</p>
<p><span class="math display">\[ E\{TSS-RSS/p\} = \sigma^2. \]</span></p>
<p>Hence, when there is no relationship between the response and predictors, one would expect the F-statistic to take on a value close to 1.
On the other hand, if <span class="math inline">\(H_a\)</span> is true, then $ E{TSS-RSS/p} &gt; ^2 $, so we expect <span class="math inline">\(F\)</span> t obe greater than 1.</p>
<p>The F-statistic for the multiple linear regression model obtained by regressing <code>sales</code> onto <code>radio</code>, <code>TV</code>, and <code>newspaper</code> is shown in Table 3.6.
In this example the F-statistic is 570.
Since this is far larger than 1, it provides compelling evidence against the null hypothesis <span class="math inline">\(H_0\)</span>.
In other words, the large F-statistic suggests that at least one of the advertising media must be related to <code>sales</code>.
However, what if the F-statistic had been closer to
1? How large does the F-statistic need to be before we can reject <span class="math inline">\(H_0\)</span> and conclude that there is a relationship?
It turns out that the answer depends on the values of <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>.
When <span class="math inline">\(n\)</span> is large, an F-statistic that is just a little larger than 1 might still provide evidence against <span class="math inline">\(H_0\)</span>.
In contrast, a larger F-statistic is needed to reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(n\)</span> is small.
When <span class="math inline">\(H_0\)</span> is true, and the errors <span class="math inline">\(\epsilon_i\)</span> have a normal distribution, the F-statistic follows an F-distribution.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>
For any given value of <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, any statistical software package can be used to compute the p-value associated with the F-statistic using this distribution.
Based on this p-value, we can determine whether or not to reject <span class="math inline">\(H_0\)</span>.
For the advertising data, the p-value associated with the F-statistic in Table 3.6 is essentially zero, so we have extremely strong evidence that at least one of the media is associated with increased <code>sales</code>.</p>
<p>In <a href="mult-lin-reg.html#eq:fstat">(2.23)</a> we are testing <span class="math inline">\(H_0\)</span> that all the coefficients are zero.
Sometimes we want to test that a partiuclar subset of <span class="math inline">\(q\)</span> of the coefficients are zero.
This corresponds to a null hypothesis</p>
<p><span class="math display">\[H_0: \beta_{p-q+1} = \beta_{p-q+2} = ... = \beta_p = 0.\]</span></p>
<p>where for convenience we have put the variables chosen for omission at the end of the list.
In this case we fit a second model that uses all the variables <em>except</em> those last <span class="math inline">\(q\)</span>.
Suppose that the residual sum of squares for that model is <span class="math inline">\(RSS_0\)</span>.
Then the appropriate F-statistic is</p>
<p><span class="math display" id="eq:fstat2">\[\begin{equation}
  F = \frac{(RSS_0 - RSS)/q}{RSS/(n-p-1)}.
  \tag{2.24}
\end{equation}\]</span></p>
<p>Notice that in Table 3.4, for each individual predictor a t-statistic and a p-value were reported.
These provide information about whether each individual predictor is related to the response, after adjusting for the other predictors.
It turns out that each of these are exactly equivalent<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> to the F-test that omits that single variable from the model, leaving all others in—i.e. <span class="math inline">\(q=1\)</span> in <a href="mult-lin-reg.html#eq:fstat2">(2.24)</a>.
So it reports the <em>partial effect</em> of adding that variable to the model.
For instance, as we discussed earlier, these p-values indicate that <code>TV</code> and <code>radio</code> are related to <code>sales</code>, but that there is no evidence that <code>newspaper</code> is associated with <code>sales</code>, in the presence of these two.</p>
<p>Given these individual p-values for each variable, why do we need to look at the overall F-statistic?
After all, it seems likely that if any one of the p-values for the individual variables is very small, then <em>at least one of the predictors is related to the response</em>.
However, this logic is flawed, especially when the number of predictors p is large.</p>
<p>For instance, consider an example in which <span class="math inline">\(p = 100\)</span> and <span class="math inline">\(H_0: \beta_1 = \beta_2 = ... = \beta_p = 0\)</span>is true, so no variable is truly associated with the response.
In this situation, about 5% of the p-values associated with each variable (of the type shown in Table 3.4) will be below 0.05 by chance.
In other words, we expect to see approximately five <em>small</em> p-values even in the absence of any true association between the predictors and the response.
In fact, we are almost guaranteed that we will observe at least one p-value below 0.05 by chance!
Hence, if we use the individual t-statistics and associated p-values in order to decide whether or not there is any association between the variables and the response, there is a very high chance that we will incorrectly conclude that there is a relationship.
However, the F-statistic does not suffer from this problem because it adjusts for the number of predictors.
Hence, if <span class="math inline">\(H_0\)</span> is true, there is only a 5% chance that the F-statistic will result in a p-value below 0.05, regardless of the number of predictors or the number of observations.</p>
<p>The approach of using an F-statistic to test for any association between the predictors and the response works when <span class="math inline">\(p\)</span> is relatively small, and certainly small compared to <span class="math inline">\(n\)</span>.
However, sometimes we have a very large number of variables.
If <span class="math inline">\(p &gt; n\)</span> then there are more coefficients <span class="math inline">\(\beta_j\)</span> to estimate than observations from which to estimate them.
In this case we cannot even fit the multiple linear regression model using least squares, so the F-statistic cannot be used, and neither can most of the other concepts that we have seen so far in this chapter.
When <span class="math inline">\(p\)</span> is large, some of the approaches discussed in the next section, such as <em>forward selection</em>, can be used.
This <strong><span style="font-family:monospace; color: #1188ce;">high-dimensional</span></strong> setting is discussed in greater detail in Chapter 6.</p>
</div>
<div id="two-deciding-on-important-variables" class="section level4">
<h4><span class="header-section-number">2.2.2.2</span> Two: Deciding on Important Variables</h4>
<p>As discussed in the previous section, the first step in a multiple regression analysis is to compute the F-statistic and to examine the associated p-value.
If we conclude on the basis of that p-value that at least one of the predictors is related to the response, then it is natural to wonder which are the guilty ones!
We could look at the individual p-values as in Table 3.4,
but as discussed, if p is large we are likely to make some false discoveries.
It is possible that all of the predictors are associated with the response, but it is more often the case that the response is only related to a subset of the predictors.
The task of determining which predictors are associated with the response, in order to fit a single model involving only those predictors, is referred to as <strong><span style="font-family:monospace; color: #1188ce;">variable selection</span></strong>.
The variable selection problem is studied extensively in Chapter 6, and so here we will provide only a brief outline of some classical approaches.</p>
<p>Ideally, we would like to perform variable selection by trying out a lot of different models, each containing a different subset of the predictors.
For instance, if <span class="math inline">\(p = 2\)</span>, then we can consider four models: (1) a model containing no variables, (2) a model containing <span class="math inline">\(X_1\)</span> only, (3) a model containing <span class="math inline">\(X_2\)</span> only, and (4) a model containing both <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.
We can then select the <em>best</em> model out of all the models that we have considered.
How do we determine which model is best?
Various statistics can be used to judge the quality of a model.
These include <span class="math inline">\(\color{#1188ce}{Mallow&#39;s\ C_p}\)</span>, <strong><span style="font-family:monospace; color: #1188ce;">Akaike information criterion</span></strong> (AIC), <strong><span style="font-family:monospace; color: #1188ce;">Bayesian information criterion</span></strong> (BIC), and <span class="math inline">\(\color{#1188ce}{adjusted\ R^2}\)</span>*.
These are discussed in more detail in Chapter 6.
We can also determine which model is best by plotting various model outputs, such as the residuals, in order to search for patterns.</p>
<p>Unfortunately, there are a total of <span class="math inline">\(2^p\)</span> models that contain subsets of <em>p</em> variables.
This means that even for moderate <em>p</em>, trying out every possible subset of predictors is infeasible.
For instance, we saw that if <em>p</em> = 2, then there are <span class="math inline">\(2^2\)</span> = 4 models to consider.
But if <em>p</em> = 30, then we must consider <span class="math inline">\(2^30\)</span> = 1,073,741824 models!
This is not practical.
Therefore, unless <em>p</em> is very small, we cannot consider all <span class="math inline">\(2^p\)</span> models, and instead we need an automated and efficient approach to choose a smaller set of models to consider.
There are three classical approaches for this task:</p>
<ul>
<li><strong><span style="font-family:monospace; color: #1188ce;">Forward selection</span></strong>.
We begin with the <strong><span style="font-family:monospace; color: #1188ce;">null model</span></strong>—a model that contains an intercept but no predictors.
We then fit <em>p</em> simple linear regressions and add to the null model the variable that results in the lowest RSS.
We then add to that model the variable that results in the lowest RSS for the new two-variable model.
This approach is continued until some stopping rule is satisfied.</li>
<li><strong><span style="font-family:monospace; color: #1188ce;">Backward selection</span></strong>.
We start with all variables in the model, and remove the variable with the largest p-value—that is, the variable that is the least statistically significant.
The new (<em>p</em> - 1)-variable model is fit, and the variable with the largest p-value is removed.
This procedure continues until a stopping rule is reached.
For instance, we may stop when all remaining variables have a p-value below some threshold.</li>
<li><strong><span style="font-family:monospace; color: #1188ce;">Mixed selection</span></strong>.
This is a combination of forward and backward selection.
We start with no variables in the model, and as with forward selection, we add the variable that provides the best fit.
We continue to add variables one-by-one.
Of course, as we noted with the <code>Advertising</code> example, the p-values for the variables can become larger as the new predictors are added to the model.
Hence, if at any point the p-value for one of the variables in the model rises above a certain threshold, then we remove that variable from the model.
We continue to perform these forward and backward steps until all variables in the model have a sufficiently low p-value, and all variables outside the model would have a large p-value if added to the model.</li>
</ul>
<p>Backward selection cannot be used if <em>p</em> &gt; <em>n</em>, while forward selection can always be used.
Forward selection is a greedy approach, and might include variables early that later become redundant.
Mixed selection can remedy this.</p>
</div>
<div id="three-model-fit" class="section level4">
<h4><span class="header-section-number">2.2.2.3</span> Three: Model Fit</h4>
<p>Two of the most common numerical measures of model fit are the RSE and
<span class="math inline">\(R^2\)</span>, the fraction of variance explained.
These quantities are computed and interpreted in the same fashion as for simple linear regression.</p>
<p>Recall that in simple regression, <span class="math inline">\(R^2\)</span> is the square of the correlation of the response and the variable.
In multiple linear regression, it turns out that it equals Cor(Y, <span class="math inline">\(\hat{Y})^2\)</span>, the square of the correlation between the response and
the fitted linear model; in fact one property of the fitted linear model is that it maximizes this correlation among all possible linear models.</p>
<p>An <span class="math inline">\(R^2\)</span> value close to 1 indicates that the model explains a large portion of the variance in the response variable.
As an example, we saw in Table 3.6 that for the <code>Advertising</code> data, the model that uses all three advertising media to predict <code>sales</code> has an <span class="math inline">\(R^2\)</span> of 0.8972.
On the other hand, the model that uses only <code>TV</code> and <code>radio</code> to predict <code>sales</code> has an <span class="math inline">\(R^2\)</span> value of 0.89719.
In other words, there is a small increase in <span class="math inline">\(R^2\)</span> if we include newspaper advertising in the model that already contains TV and radio advertising, even though we saw earlier that the p-value for newspaper advertising in Table 3.4 is not significant.
It turns out that <span class="math inline">\(R^2\)</span> will always increase when more variables are added to the model, even if those variables are only weakly associated with the response.
This is due to the fact that adding another variable to the least squares equations must allow us to fit the training data (though not necessarily the testing data) more accurately.
Thus, the <span class="math inline">\(R^2\)</span> statistic, which is also computed on the training data, must increase.
The fact that adding newspaper advertising to the model containing only TV and radio advertising leads to just a tiny increase in <span class="math inline">\(R^2\)</span> provides additional evidence that <code>newspaper</code> can be dropped from the model.
Essentially, <code>newspaper</code> provides no real improvement in the model fit to the training samples, and its inclusion will likely lead to poor results on independent test samples due to overfitting.</p>
<p>In contrast, the model containing only <code>TV</code> as a predictor had an <span class="math inline">\(R^2\)</span> of 0.61 (Table 3.2).
Adding <code>radio</code> to the model leads to a substantial improvement in <span class="math inline">\(R^2\)</span>.
This implies that a model that uses TV and radio expenditures to predict sales is substantially better than one that uses only TV advertising.
We could further quantify this improvement by looking at the p-value for the <code>radio</code> coefficient in a model that contains only <code>TV</code> and <code>radio</code> as predictors.</p>
<p>The model that contains only <code>TV</code> and <code>radio</code> as predictors has an RSE of 1.681, and the model that also contains <code>newspaper</code> as a predictor has an RSE of 1.686 (Table 3.6).
In contrast, the model that contains only <code>TV</code> has an RSE of 3.26 (Table 3.2).
This corroborates our previous conclusion that a model that uses TV and radio expenditures to predict sales is much more accurate (on the training data) than one that only uses TV spending.
Furthermore, given that TV and radio expenditures are used as predictors, there is no point in also using newspaper spending as a predictor in the model.
The observant reader may wonder how RSE can increase when <code>newspaper</code> is added to the model given that RSS must decrease.
In general RSE is defined as</p>
<p><span class="math display" id="eq:rse-def">\[\begin{equation}
  RSE = \sqrt{\frac{1}{n-p-1}RSS,}
  \tag{2.25}
\end{equation}\]</span></p>
<p>which simplifies to <a href="simple-lin-reg.html#eq:rse">(2.15)</a> for a simple linear regression.
Thus, models with more variables can have higher RSE if the decrease in RSS is small relative to the increaes in <em>p</em>.</p>
<p>In addition to looking at the RSE and <span class="math inline">\(R^2\)</span> statistics just discussed, it can be useful to plot the data.
Graphical summaries can reveal problems with a model that are not visible from numerical statistics.
For example, Figure 3.5 displays a three-dimensional plot of <code>TV</code> and <code>radio</code> versus <code>sales</code>.
We see that some observations lie above and some observations lie below the least squares regression plane.
In particular, the linear model seems to overestimate <code>sales</code> for instances in which most of the advertising money was spent exclusively on either <code>TV</code> or <code>radio</code>.
It underestimates <code>sales</code> for instances where the budget was split between the two media.
This pronounced non-linear pattern cannot be modeled accurately using linear regression.
It suggests a <em>synergy</em> or <em>interaction</em> effect between the advertising media, whereby combining the media together results in a bigger boost to sales than using any single medium.
In Section 3.3.2, we will discuss extending the linear model to accomodate such synergistic effects through the use of interaction terms.</p>
</div>
<div id="four-predictions" class="section level4">
<h4><span class="header-section-number">2.2.2.4</span> Four: Predictions</h4>
<p>Once we have fit the multiple regression model, it is straightforward to apply <a href="mult-lin-reg.html#eq:mlin-reg-est">(2.21)</a> in order to predict the response <em>Y</em> on the basis of a set of values for the predictors <span class="math inline">\(X_1, X_2,...,X_p\)</span>.
However, there are three sorts of uncertainty associated with this prediction.</p>
<ol style="list-style-type: decimal">
<li>The coefficient estimates <span class="math inline">\(\hat{\beta_0}, \hat{\beta_1}, ... , \hat{\beta_p}\)</span> are estimates for <span class="math inline">\(\beta_0, \beta_1, ... , \beta_p\)</span>.
That is, the <em>least squares plane</em></li>
</ol>
<p><span class="math display">\[ \hat{Y} = \hat{\beta_0} + \hat{\beta_1}X_1 + ... + \hat{\beta_p}X_p\]</span></p>
<p>is only an estimate for the <em>true population regression plane</em></p>
<p><span class="math display">\[f(X) = \beta_0 + \beta_1 X1 + ... + \beta_p X_p.\]</span></p>
<p>The inaccuracy in the coefficient estimates is related to the <em>reducible error</em> from Chapter 2.
We can compute a <em>confidence interval</em> in order to determine how close <span class="math inline">\(\hat{Y}\)</span> will be to <span class="math inline">\(f(X)\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Of course, in practice assuming a linear model for <span class="math inline">\(f(X)\)</span> is almost always an approximation of reality, so there is an additional source of potentially reducible error which we call <em>model bias</em>.
So when we use a linear model, we are in fact estimating the best linear approximation to the true surface.
However, here we will ignore this discrepancy, and operate as if the linear model were correct.</p></li>
<li><p>Even if we knew <span class="math inline">\(f(X)\)</span>—that is, even if we knew the true values for <span class="math inline">\(\beta_0, \beta_1,...,\beta_p\)</span>—the response value cannot be predicted perfectly because of the random error in the model <a href="mult-lin-reg.html#eq:mlin-reg-est">(2.21)</a>.
In Chapter 2, we referred to this as the irreducible error.
How much will Y vary from <span class="math inline">\(\hat{Y}\)</span>?
We use prediction intervals to answer this question.
Prediction intervals are always wider than confidence intervals, because they incorporate both the error in the estimate for f(X) (the reducible error) and the uncertainty as to how much an individual point will differ from the population regression plane (the irreducible error).</p></li>
</ol>
<p>We use a <strong><span style="font-family:monospace; color: #1188ce;">confidence interval</span></strong> to quantify the uncertainty surrounding the <em>average</em> <code>sales</code> over a large number of cities.
For example, given that $100,000 is spent on <code>TV</code> advertising and $20,000 is spent on <code>radio</code> advertising in each city, the 95% confidence interval is [10,985, 11,528].
We interpret this to mean that 95% of intervals of this form will contain the true value of f(X).<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>
On the other hand, a <strong><span style="font-family:monospace; color: #1188ce;">prediction interval</span></strong> can be used to quantify the uncertainty surrounding <code>sales</code> for a <em>particular</em> city.
Given that $100,000 is spent on <code>TV</code> advertising and $20,000 is spent on <code>radio</code> advertising in that city the 95% prediction interval is [7,930, 14,580].
We interpret this to mean that 95% of intervals of this form will contain the true value of <em>Y</em> for this city.
Note that both intervals are centered at 11,256, but that the prediction interval is substantially wider than the confidence interval, reflecting the increased uncertainty about <code>sales</code> for a given city in comparison to the average <code>sales</code> over many locations.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Even if the errors are not normally-distributed, the F-statistic approximately follows an F-distribution provided that the sample size <span class="math inline">\(n\)</span> is large.<a href="mult-lin-reg.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>The squar eof each t-statistic is the corresponding F-statistic.<a href="mult-lin-reg.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>In other words, if we collect a large number of data sets like the <code>Advertising</code> data set, and we construct a confidence interval for the average <code>sales</code> on the basis of each data set (given $100,000 in <code>TV</code> and $20,000 in <code>radio</code> advertising), then 95% of these confidence intervals will contain the true value of average <code>sales</code><a href="mult-lin-reg.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simple-lin-reg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="other-reg-cons.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BookdownISL.pdf", "BookdownISL.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
