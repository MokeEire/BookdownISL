<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.1 Simple Linear Regression | An Introduction to Statistical Learning: with Applications in R</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3.1 Simple Linear Regression | An Introduction to Statistical Learning: with Applications in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.1 Simple Linear Regression | An Introduction to Statistical Learning: with Applications in R" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Gareth James, Daniela Witten, Trevor Hastie, &amp; Robert Tibshirani" />


<meta name="date" content="2020-06-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linreg.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="3.1.1" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#simple-coef-est"><i class="fa fa-check"></i><b>3.1.1</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-lin-reg.html"><a href="simple-lin-reg.html#assess-coef-acc"><i class="fa fa-check"></i><b>3.1.2</b> Assessing the Accuracy of the Coefficient Estimates</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning: with Applications in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-lin-reg" class="section level2">
<h2><span class="header-section-number">3.1</span> Simple Linear Regression</h2>
<p><em>Simple linear regression</em> lives up to its name: it is a very straightforward approach for predicting a quantitative response <em>Y</em> on the basis of a single predictor variable <em>X</em>.
It assumes that there is an approximately linear relationship between <em>X</em> and <em>Y</em>.
Mathematically we can write this linear relationship as</p>
<p><span class="math display" id="eq:linmod">\[\begin{equation} 
  Y \approx \beta_0 + \beta_1X
  \tag{3.1}
\end{equation}\]</span></p>
<p>You might read “<span class="math inline">\(\approx\)</span>” as “<em>is approximately modeled as</em>”.
We will sometimes describe <a href="simple-lin-reg.html#eq:linmod">(3.1)</a> by saying we are <em>regressing</em> Y on X (or Y <em>onto</em> X).
For example, <em>X</em> may represent <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> advertising and <em>Y</em> may represent <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong>.
Then we can regress <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> onto <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> by fitting the model:</p>
<p><span class="math display">\[\textbf{sales} = \beta_0+\beta_1\times\textbf{TV}\]</span></p>
<p>In Equation <a href="simple-lin-reg.html#eq:linmod">(3.1)</a>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are two unknown constants that represent the <em>intercept</em> and the <em>slope</em> terms in the linear model.
Together, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are known as the model <em>coefficients</em> or <em>parameters</em>.
Once we have used our training data to produce estimates <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> for our model parameters, we can predict future sales on the basis of a particular value of TV advertising by computing</p>
<p><span class="math display" id="eq:linest">\[\begin{equation} 
  \hat{y} = \hat{\beta_0} + \hat{\beta_1}x
  \tag{3.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\hat{y}\)</span> indicates a prediction of <span class="math inline">\(Y\)</span> on the basis of <span class="math inline">\(X=x\)</span>.
Here we use the <em>hat</em> symbol, ^ , to denote the estimated value of an unknown parameter or coefficient, or to denote the predicted value of the response.</p>
<div id="simple-coef-est" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Estimating the Coefficients</h3>
<p>In practice, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown.
So before we can use <a href="simple-lin-reg.html#eq:linmod">(3.1)</a> to make predictions, we must use data to estimate the coefficients. Let</p>
<p><span class="math display">\[(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\]</span></p>
<p>represent <em>n</em> observation pairs, each of which consists of a measurement of <em>X</em> and a measurement of <em>Y</em>.
In the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> example, this data set consists of the TV advertising budget and product sales in <span class="math inline">\(n = 200\)</span> different markets.
(Recall that the data are displayed in <strong>Figure 2.1</strong>.)
Our goal is to obtain coefficient estimates <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> such that the linear model <a href="simple-lin-reg.html#eq:linmod">(3.1)</a> fits the available data well—that is, so that <span class="math inline">\(y_i \approx \hat{\beta_0}+\hat{\beta_1}x_i\)</span> for <span class="math inline">\(i = 1,...,n\)</span>.
In other words, we want to find an intercept b0 and a slope b1 such that the resulting line is as close as possible to the <span class="math inline">\(n = 200\)</span> data points.
There are a number of ways of measuring <em>closeness</em>.
However, by far the most common approach involves minimizing the <em>least squares</em> criterion, and we take that approach in this chapter.
Alternative approaches will be considered in Chapter 6.</p>
<div class="figure" style="text-align: center"><span id="fig:advertising-lm"></span>
<img src="BookdownISL_files/figure-html/advertising-lm-1.png" alt="*For the &lt;strong&gt;&lt;span style='font-family:monospace; color: #B44C1C;'&gt;Advertising&lt;/span&gt;&lt;/strong&gt; data, the least squares fit for the regression of &lt;strong&gt;&lt;span style='font-family:monospace; color: #B44C1C;'&gt;sales&lt;/span&gt;&lt;/strong&gt; onto &lt;strong&gt;&lt;span style='font-family:monospace; color: #B44C1C;'&gt;TV&lt;/span&gt;&lt;/strong&gt; is shown.  The fit is found by minimizing the sum of squared errors.  Each grey line segment represents an error, and the fit makes a compromise by averaging their squares.  In this case a linear fit captures the essence of the relationship, although it is somewhat deficient in the left of the plot.*" width="1152" />
<p class="caption">
Figure 3.1: <em>For the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> data, the least squares fit for the regression of <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> onto <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> is shown. The fit is found by minimizing the sum of squared errors. Each grey line segment represents an error, and the fit makes a compromise by averaging their squares. In this case a linear fit captures the essence of the relationship, although it is somewhat deficient in the left of the plot.</em>
</p>
</div>
<p>Let <span class="math inline">\(\hat{y_i} = \hat{\beta_0}+\hat{\beta_1}x_i\)</span> be the prediction for <span class="math inline">\(Y\)</span> based on the <em>i</em>th value of <span class="math inline">\(X\)</span>.
Then <span class="math inline">\(e_i = y_i - \hat{y_i}\)</span> represents the <em>i</em>th <em>residual</em>—this is the difference between the <em>i</em>th observed response value and the <em>i</em>th response value that is predicted by our linear model.
We define the <em>residual sum of squares</em> (RSS) as
<span class="math display">\[RSS = {e_1^2}+{e_2^2}+...+{e_n^2},\]</span>
or equivalently as</p>
<p><span class="math display" id="eq:rss">\[\begin{equation} 
  RSS = (y_1 - \hat{\beta_0} - \hat{\beta_1}x_1)^2 + (y_2 - \hat{\beta_0} - \hat{\beta_1}x_2)^2 + ... + (y_n - \hat{\beta_0} - \hat{\beta_1}x_n)^2.
  \tag{3.3}
\end{equation}\]</span></p>
<p>The least squares approach chooses <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> to minimize the RSS.
Using some calculus, one can show that the minimizers are</p>
<p><span class="math display" id="eq:rssmin">\[\begin{equation} 
\begin{aligned}
  \hat{\beta_1} &amp;= \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2},\\
  \hat{\beta_0} &amp;= \bar{y}-\hat{\beta_1}\bar{x},
  \end{aligned}
  \tag{3.4}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\bar{y} \equiv \frac{1}{n}\sum_{i=1}^{n}y_i\)</span> and <span class="math inline">\(\bar{x} \equiv \frac{1}{n}\sum_{i=1}^{n}x_i\)</span> are the sample means.
In other words, <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a> defines the <em>least squares coefficient estimates</em> for simple linear regression.</p>
<p>(fig:advertising-lm) displays the simple linear regression fit to the <strong><span style="font-family:monospace; color: #B44C1C;">Advertising</span></strong> data, where <span class="math inline">\(\hat{\beta_0} = 7.03\)</span> and <span class="math inline">\(\hat{\beta_1} = 0.0475\)</span>.
In other words, according to this approximation, an additional $1,000 spent on TV advertising is associated with selling approximately 47.5 additional units of the product.
In <strong>Figure 3.2</strong>, we have computed RSS for a number of values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, using the advertising data with <strong><span style="font-family:monospace; color: #B44C1C;">sales</span></strong> as the response and <strong><span style="font-family:monospace; color: #B44C1C;">TV</span></strong> as the predictor.
In each plot, the red dot represents the pair of least squares estimates <span class="math inline">\((\hat{\beta_0}, \hat{\beta_1})\)</span> given by <a href="simple-lin-reg.html#eq:rssmin">(3.4)</a>.
These values clearly minimize the RSS.</p>
</div>
<div id="assess-coef-acc" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Assessing the Accuracy of the Coefficient Estimates</h3>
<p>Recall from <strong>Equation (2.1)</strong> that we can assume that the <em>true</em> relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> takes the form <span class="math inline">\(Y = f(X)+\epsilon\)</span> for some unknown function <span class="math inline">\(f\)</span>, where <span class="math inline">\(\epsilon\)</span> is a mean-zero random error term.
If <span class="math inline">\(f\)</span> is to be approximated by a linear function, then we can write this relationship as</p>
<p><span class="math display" id="eq:lin-rel">\[\begin{equation}
  Y = \beta_0+\beta_1X + \epsilon.
  \tag{3.5}
\end{equation}\]</span></p>
<p>Here <span class="math inline">\(\beta_0\)</span> is the intercept term—that is, the expected value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X=0\)</span> and <span class="math inline">\(\beta_1\)</span> is the slope—the average increase in <span class="math inline">\(Y\)</span> associated with a one-unit increase in <span class="math inline">\(X\)</span>.
The error term is a catch-all for what we miss with this simple model: the true relationship is probably not linear, there may be other variables that cause variation in <span class="math inline">\(Y\)</span>, and there may be measurement error.
We typically assume that the error term is independent of <span class="math inline">\(X\)</span>.
The model given by (eq:lin-rel) defines the <em>population regression line</em>, which is the best linear approximation to the true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
The least squares regression coefficient estimates (eq:rssmin) characterize the <em>least squares line</em> (eq:linest).
The left-hand panel of <strong>Figure 3.3</strong> displays these two lines in a simple simulated example. We created 100 random Xs, and generated 100 corresponding Ys from the model</p>
<p><span class="math display" id="eq:sim-mod">\[\begin{equation}
  Y = 2+3X+\epsilon
  \tag{3.6}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> was generated from a normal distribution with mean zero.</p>

<div id="refs" class="references">
<div>
<p>Xie, Yihui. 2015. <em>Dynamic Documents with R and Knitr</em>. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. <a href="http://yihui.org/knitr/">http://yihui.org/knitr/</a>.</p>
</div>
<div>
<p>———. 2020. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
</div>
</div>
<!-- </div> -->







<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The assumption of linearity is often a useful working model.
However, despite what many textbooks might tell us, we seldom believe that the true relationship is linear.<a href="simple-lin-reg.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linreg.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BookdownISL.pdf", "BookdownISL.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
